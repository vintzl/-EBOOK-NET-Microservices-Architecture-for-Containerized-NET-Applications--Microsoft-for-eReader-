<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
  <head>
    <title>Unknown</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<p id="id_Toc534713535" class="block_16">Architecting container and microservice-based applications</p>
	<p class="block_26">Microservices offer great benefits but also raise huge new challenges. Microservice architecture patterns are fundamental pillars when creating a microservice-based application.</p>
	<p class="block_14">Earlier in this guide, you learned basic concepts about containers and Docker. That was the minimum information you needed to get started with containers. Although, even when containers are enablers and a great fit for microservices, they aren’t mandatory for a microservice architecture and many architectural concepts in this architecture section could be applied without containers, too. However, this guidance focuses on the intersection of both due to the already introduced importance of containers.</p>
	<p class="block_14">Enterprise applications can be complex and are often composed of multiple services instead of a single service-based application. For those cases, you need to understand additional architectural approaches, such as the microservices and certain Domain-Driven Design (DDD) patterns plus container orchestration concepts. Note that this chapter describes not just microservices on containers, but any containerized application, as well.</p>
	<h2 id="id_Toc534713536" class="block_18">Container design principles</h2>
	<p class="block_14">In the container model, a container image instance represents a single process. By defining a container image as a process boundary, you can create primitives that can be used to scale the process or to batch it.</p>
	<p class="block_17"><span class="text_5">When you design a container image, you’ll see an </span><a href="https://docs.docker.com/engine/reference/builder/" class="text_4">ENTRYPOINT</a><span class="text_5"> definition in the Dockerfile. This defines the process whose lifetime controls the lifetime of the container. When the process completes, the container lifecycle ends. Containers might represent long-running processes like web servers, but can also represent short-lived processes like batch jobs, which formerly might have been implemented as Azure </span><a href="https://github.com/Azure/azure-webjobs-sdk/wiki" class="text_4">WebJobs</a><span class="text_5">.</span></p>
	<p class="block_14">If the process fails, the container ends, and the orchestrator takes over. If the orchestrator was configured to keep five instances running and one fails, the orchestrator will create another container instance to replace the failed process. In a batch job, the process is started with parameters. When the process completes, the work is complete. This guidance drills-down on orchestrators, later on.</p>
	<p class="block_17"><span class="text_5">You might find a scenario where you want multiple processes running in a single container. For that scenario, since there can be only one entry point per container, you could run a script within the container that launches as many programs as needed. For example, you can use </span><a href="http://supervisord.org/" class="text_4">Supervisor</a><span class="text_5"> or a similar tool to take care of launching multiple processes inside a single container. However, even though you can find architectures that hold multiple processes per container, that approach isn’t very common.</span></p>
	<h1 id="id_Toc534713537" class="block_24">Containerizing monolithic applications</h1>
	<p class="block_14">You might want to build a single, monolithically deployed web application or service and deploy it as a container. The application itself might not be internally monolithic, but structured as several libraries, components, or even layers (application layer, domain layer, data-access layer, etc.). Externally, however, it’s a single container—a single process, a single web application, or a single service.</p>
	<p class="block_14">To manage this model, you deploy a single container to represent the application. To increase capacity, you scale out, that is, just add more copies with a load balancer in front. The simplicity comes from managing a single deployment in a single container or VM.</p>
	<p class="block_14"><img src="images/image-5.png" alt="C:\Users\Miguel\source\repos\dotnet\docs\docs\standard\microservices-architecture\architect-microservice-container-applications\media\image1.png" class="calibre17"/></p>
	<p class="block_23"><span class="text_6">Figure 4-1</span><i class="calibre8">. Example of the architecture of a containerized monolithic application</i></p>
	<p class="block_14">You can include multiple components, libraries, or internal layers in each container, as illustrated in Figure 4-1. However, this monolithic pattern might conflict with the container principle “a container does one thing, and does it in one process”, but might be ok for some cases.</p>
	<p class="block_14">The downside of this approach becomes evident if the application grows, requiring it to scale. If the entire application can scale, it isn’t really a problem. However, in most cases, just a few parts of the application are the choke points that requiring scaling, while other components are used less.</p>
	<p class="block_14">For example, in a typical e-commerce application, you likely need to scale the product information subsystem, because many more customers browse products than purchase them. More customers use their basket than use the payment pipeline. Fewer customers add comments or view their purchase history. And you might have only a handful of employees, that need to manage the content and marketing campaigns. If you scale the monolithic design, all the code for these different tasks is deployed multiple times and scaled at the same grade.</p>
	<p class="block_14">There are multiple ways to scale an application-horizontal duplication, splitting different areas of the application, and partitioning similar business concepts or data. But, in addition to the problem of scaling all components, changes to a single component require complete retesting of the entire application, and a complete redeployment of all the instances.</p>
	<p class="block_14">However, the monolithic approach is common, because the development of the application is initially easier than for microservices approaches. Thus, many organizations develop using this architectural approach. While some organizations have had good enough results, others are hitting limits. Many organizations designed their applications using this model because tools and infrastructure made it too difficult to build service-oriented architectures (SOA) years ago, and they did not see the need-until the application grew.</p>
	<p class="block_14">From an infrastructure perspective, each server can run many applications within the same host and have an acceptable ratio of efficiency in resources usage, as shown in Figure 4-2.</p>
	<p class="block_14"><img src="images/image-6.png" alt="C:\Users\Miguel\source\repos\dotnet\docs\docs\standard\microservices-architecture\architect-microservice-container-applications\media\image2.png" class="calibre18"/></p>
	<p class="block_23"><span class="text_6">Figure 4-2</span><i class="calibre8">. Monolithic approach: Host running multiple apps, each app running as a container</i></p>
	<p class="block_17"><span class="text_5">Monolithic applications in Microsoft Azure can be deployed using dedicated VMs for each instance. Additionally, using </span><a href="https://azure.microsoft.com/documentation/services/virtual-machine-scale-sets/" class="text_4">Azure virtual machine scale sets</a><span class="text_5">, you can easily scale the VMs. </span><a href="https://azure.microsoft.com/services/app-service/" class="text_4">Azure App Service</a><span class="text_5"> can also run monolithic applications and easily scale instances without requiring you to manage the VMs. Since 2016, Azure App Services can run single instances of Docker containers as well, simplifying deployment.</span></p>
	<p class="block_14">As a QA environment or a limited production environment, you can deploy multiple Docker host VMs and balance them using the Azure balancer, as shown in Figure 4-3. This lets you manage scaling with a coarse-grain approach, because the whole application lives within a single container.</p>
	<p class="block_14"><img src="images/image-7.png" alt="C:\Users\Miguel\source\repos\dotnet\docs\docs\standard\microservices-architecture\architect-microservice-container-applications\media\image3.png" class="calibre19"/></p>
	<p class="block_23"><span class="text_6">Figure 4-3</span><i class="calibre8">. Example of multiple hosts scaling up a single container application</i></p>
	<p class="block_27"><span class="text_8">Deployment to the various hosts can be managed with traditional deployment techniques. Docker hosts can be managed with commands like </span><span class="text_9">docker run</span><span class="text_8"> or </span><span class="text_9">docker-compose</span><span class="text_8"> performed manually, or through automation such as continuous delivery (CD) pipelines.</span></p>
	<h2 id="id_Toc534713538" class="block_18">Deploying a monolithic application as a container</h2>
	<p class="block_14">There are benefits to using containers to manage monolithic application deployments. Scaling container instances is far faster and easier than deploying additional VMs. Even if you use virtual machine scale sets, VMs take time to start. When deployed as traditional application instances instead of containers, the configuration of the application is managed as part of the VM, which isn’t ideal.</p>
	<p class="block_27"><span class="text_8">Deploying updates as Docker images is far faster and network efficient. Docker images typically start in seconds, which speeds rollouts. Tearing down a Docker image instance is as easy as issuing a </span><span class="text_9">docker stop</span><span class="text_8"> command, and typically completes in less than a second.</span></p>
	<p class="block_14">Because containers are immutable by design, you never need to worry about corrupted VMs. In contrast, update scripts for a VM might forget to account for some specific configuration or file left on disk.</p>
	<p class="block_14">While monolithic applications can benefit from Docker, we’re touching only on the benefits. Additional benefits of managing containers come from deploying with container orchestrators, which manage the various instances and lifecycle of each container instance. Breaking up the monolithic application into subsystems that can be scaled, developed, and deployed individually is your entry point into the realm of microservices.</p>
	<h2 id="id_Toc534713539" class="block_18">Publishing a single-container-based application to Azure App Service</h2>
	<p class="block_14">Whether you want to get validation of a container deployed to Azure or when an application is simply a single-container application, Azure App Service provides a great way to provide scalable single-container-based services. Using Azure App Service is simple. It provides great integration with Git to make it easy to take your code, build it in Visual Studio, and deploy it directly to Azure.</p>
	<p class="block_14"><img src="images/image-8.png" alt="C:\Users\Miguel\source\repos\dotnet\docs\docs\standard\microservices-architecture\architect-microservice-container-applications\media\image4.png" class="calibre20"/></p>
	<p class="block_23"><span class="text_6">Figure 4-4</span><i class="calibre8">. Publishing a single-container application to Azure App Service from Visual Studio</i></p>
	<p class="block_14">Without Docker, if you needed other capabilities, frameworks, or dependencies that aren’t supported in Azure App Service, you had to wait until the Azure team updated those dependencies in App Service. Or you had to switch to other services like Azure Service Fabric, Azure Cloud Services, or even VMs, where you had further control and you could install a required component or framework for your application.</p>
	<p class="block_14">Container support in Visual Studio 2017 gives you the ability to include whatever you want in your application environment, as shown in Figure 4-4. Since you’re running it in a container, if you add a dependency to your application, you can include the dependency in your Dockerfile or Docker image.</p>
	<p class="block_14">As also shown in Figure 4-4, the publish flow pushes an image through a container registry. This can be the Azure Container Registry (a registry close to your deployments in Azure and secured by Azure Active Directory groups and accounts), or any other Docker registry, like Docker Hub or an on-premises registry.</p>
	<h1 id="id_Toc534713540" class="block_24">State and data in Docker applications</h1>
	<p class="block_14">In most cases, you can think of a container as an instance of a process. A process doesn’t maintain persistent state. While a container can write to its local storage, assuming that an instance will be around indefinitely would be like assuming that a single location in memory will be durable. You should assume that container images, like processes, have multiple instances or will eventually be killed. If they’re managed with a container orchestrator, you should assume that they might get moved from one node or VM to another.</p>
	<p class="block_14">The following solutions are used to manage persistent data in Docker applications:</p>
	<p class="block_17"><span class="text_5">From the Docker host, as </span><a href="https://docs.docker.com/engine/admin/volumes/" class="text_4">Docker Volumes</a><span class="text_5">:</span></p>
	<ul class="list_">
	<li class="block_25"><b class="calibre1">Volumes</b> are stored in an area of the host filesystem that’s managed by Docker.</li>
	<li class="block_25"><b class="calibre1">Bind mounts</b> can map to any folder in the host filesystem, so access can’t be controlled from Docker process and can pose a security risk as a container could access sensitive OS folders.</li>
	<li class="block_25"><b class="calibre1">tmpfs mounts</b> are like virtual folders that only exist in the host’s memory and are never written to the filesystem.</li>
</ul>
	<p class="block_14">From remote storage:</p>
	<ul class="list_">
	<li class="block_20"><a href="https://azure.microsoft.com/documentation/services/storage/" class="text_1">Azure Storage</a><span class="text_">, which provides geo-distributable storage, providing a good long-term persistence solution for containers.</span></li>
	<li class="block_20"><span class="text_">Remote relational databases like </span><a href="https://azure.microsoft.com/services/sql-database/" class="text_1">Azure SQL Database</a><span class="text_"> or NoSQL databases like </span><a href="https://docs.microsoft.com/azure/cosmos-db/introduction" class="text_1">Azure Cosmos DB</a><span class="text_">, or cache services like </span><a href="https://redis.io/" class="text_1">Redis</a><span class="text_">.</span></li>
</ul>
	<p class="block_14">From the Docker container:</p>
	<p class="block_28">Docker provides a feature named the overlay file system. This implements a copy-on-write task that stores updated information to the root file system of the container. That information is in addition to the original image on which the container is based. If the container is deleted from the system, those changes are lost. Therefore, while it’s possible to save the state of a container within its local storage, designing a system around this would conflict with the premise of container design, which by default is stateless.</p>
	<p class="block_29"><span class="text_10">However, the previously introduced Docker Volumes is now the preferred way to handling local data Docker. If you need more information about storage in containers check on </span><a href="https://docs.docker.com/storage/storagedriver/select-storage-driver/" class="text_11">Docker storage drivers</a><span class="text_10"> and </span><a href="https://docs.docker.com/storage/storagedriver/" class="text_11">About storage drivers</a><span class="text_10">.</span></p>
	<p class="block_14">The following provides more detail about these options:</p>
	<p class="block_14"><b class="calibre5">Volumes</b> are directories mapped from the host OS to directories in containers. When code in the container has access to the directory, that access is actually to a directory on the host OS. This directory is not tied to the lifetime of the container itself, and the directory is managed by Docker and isolated from the core functionality of the host machine. Thus, data volumes are designed to persist data independently of the life of the container. If you delete a container or an image from the Docker host, the data persisted in the data volume isn’t deleted.</p>
	<p class="block_14">Volumes can be named or anonymous (the default). Named volumes are the evolution of <b class="calibre5">Data Volume Containers</b> and make it easy to share data between containers. Volumes also support volume drivers, that allow you to store data on remote hosts, among other options.</p>
	<p class="block_14"><b class="calibre5">Bind mounts</b> are available since a long time ago and allow the mapping of any folder to a mount point in a container. Bind mounts have more limitations than volumes and some important security issues, so volumes are the recommended option.</p>
	<p class="block_14"><b class="calibre5">tmpfs mounts</b> are basically virtual folders that live only in the host’s memory and are never written to the filesystem. They are fast and secure but use memory and are only meant for non-persistent data.</p>
	<p class="block_14">As shown in Figure 4-5, regular Docker volumes can be stored outside of the containers themselves but within the physical boundaries of the host server or VM. However, Docker containers can’t access a volume from one host server or VM to another. In other words, with these volumes, it isn’t possible to manage data shared between containers that run on different Docker hosts, although it could be achieved with a volume driver that supports remote hosts.</p>
	<p class="block_14"><img src="images/image-9.png" alt="C:\Users\Miguel\source\repos\dotnet\docs\docs\standard\microservices-architecture\architect-microservice-container-applications\media\image5.png" class="calibre21"/></p>
	<p class="block_23"><span class="text_6">Figure 4-5</span><i class="calibre8">. Volumes and external data sources for container-based applications</i></p>
	<p class="block_14">In addition, when Docker containers are managed by an orchestrator, containers might “move” between hosts, depending on the optimizations performed by the cluster. Therefore, it isn’t recommended that you use data volumes for business data. But they’re a good mechanism to work with trace files, temporal files, or similar that will not impact business data consistency.</p>
	<p class="block_14"><b class="calibre5">Remote data sources and cache</b> tools like Azure SQL Database, Azure Cosmos DB, or a remote cache like Redis can be used in containerized applications the same way they are used when developing without containers. This is a proven way to store business application data.</p>
	<p class="block_14"><b class="calibre5">Azure Storage.</b> Business data usually will need to be placed in external resources or databases, like Azure Storage. Azure Storage, in concrete, provides the following services in the cloud:</p>
	<ul class="list_">
	<li class="block_25">Blob storage stores unstructured object data. A blob can be any type of text or binary data, such as document or media files (images, audio, and video files). Blob storage is also referred to as Object storage.</li>
	<li class="block_25">File storage offers shared storage for legacy applications using standard SMB protocol. Azure virtual machines and cloud services can share file data across application components via mounted shares. On-premises applications can access file data in a share via the File service REST API.</li>
	<li class="block_25">Table storage stores structured datasets. Table storage is a NoSQL key-attribute data store, which allows rapid development and fast access to large quantities of data.</li>
</ul>
	<p class="block_14"><b class="calibre5">Relational databases and NoSQL databases.</b> There are many choices for external databases, from relational databases like SQL Server, PostgreSQL, Oracle, or NoSQL databases like Azure Cosmos DB, MongoDB, etc. These databases are not going to be explained as part of this guide since they are in a completely different subject.</p>
	<h1 id="id_Toc534713541" class="block_24">Service-oriented architecture</h1>
	<p class="block_14">Service-oriented architecture (SOA) was an overused term and has meant different things to different people. But as a common denominator, SOA means that you structure your application by decomposing it into multiple services (most commonly as HTTP services) that can be classified as different types like subsystems or tiers.</p>
	<p class="block_14">Those services can now be deployed as Docker containers, which solves deployment issues, because all the dependencies are included in the container image. However, when you need to scale up SOA applications, you might have scalability and availability challenges if you’re deploying based on single Docker hosts. This is where Docker clustering software or an orchestrator can help you, as explained in later sections where deployment approaches for microservices are described.</p>
	<p class="block_14">Docker containers are useful (but not required) for both traditional service-oriented architectures and the more advanced microservices architectures.</p>
	<p class="block_17"><span class="text_5">Microservices derive from SOA, but SOA is different from microservices architecture. Features like large central brokers, central orchestrators at the organization level, and the </span><a href="https://en.wikipedia.org/wiki/Enterprise_service_bus" class="text_4">Enterprise Service Bus (ESB)</a><span class="text_5"> are typical in SOA. But in most cases, these are anti-patterns in the microservice community. In fact, some people argue that “The microservice architecture is SOA done right.”</span></p>
	<p class="block_14">This guide focuses on microservices, because a SOA approach is less prescriptive than the requirements and techniques used in a microservice architecture. If you know how to build a microservice-based application, you also know how to build a simpler service-oriented application.</p>
	<h1 id="id_Toc534713542" class="block_24">Microservices architecture</h1>
	<p class="block_17"><span class="text_5">As the name implies, a microservices architecture is an approach to building a server application as a set of small services. That means a microservices architecture is mainly oriented to the back-end, although the approach is also being used for the front end. Each service runs in its own process and communicates with other processes using protocols such as HTTP/HTTPS, WebSockets, or </span><a href="https://en.wikipedia.org/wiki/Advanced_Message_Queuing_Protocol" class="text_4">AMQP</a><span class="text_5">. Each microservice implements a specific end-to-end domain or business capability within a certain context boundary, and each must be developed autonomously and be deployable independently. Finally, each microservice should own its related domain data model and domain logic (sovereignty and decentralized data management) and could be based on different data storage technologies (SQL, NoSQL) and different programming languages.</span></p>
	<p class="block_14">What size should a microservice be? When developing a microservice, size shouldn’t be the important point. Instead, the important point should be to create loosely coupled services so you have autonomy of development, deployment, and scale, for each service. Of course, when identifying and designing microservices, you should try to make them as small as possible as long as you don’t have too many direct dependencies with other microservices. More important than the size of the microservice is the internal cohesion it must have and its independence from other services.</p>
	<p class="block_14">Why a microservices architecture? In short, it provides long-term agility. Microservices enable better maintainability in complex, large, and highly-scalable systems by letting you create applications based on many independently deployable services that each have granular and autonomous lifecycles.</p>
	<p class="block_14">As an additional benefit, microservices can scale out independently. Instead of having a single monolithic application that you must scale out as a unit, you can instead scale out specific microservices. That way, you can scale just the functional area that needs more processing power or network bandwidth to support demand, rather than scaling out other areas of the application that don’t need to be scaled. That means cost savings because you need less hardware.</p>
	<p class="block_14"><img src="images/image-10.png" alt="C:\Users\Miguel\source\repos\dotnet\docs\docs\standard\microservices-architecture\architect-microservice-container-applications\media\image6.png" class="calibre22"/></p>
	<p class="block_23"><span class="text_6">Figure 4-6</span><i class="calibre8">. Monolithic deployment versus the microservices approach</i></p>
	<p class="block_14">As Figure 4-6 shows, the microservices approach allows agile changes and rapid iteration of each microservice, because you can change specific, small areas of complex, large, and scalable applications.</p>
	<p class="block_14">Architecting fine-grained microservices-based applications enables continuous integration and continuous delivery practices. It also accelerates delivery of new functions into the application. Fine-grained composition of applications also allows you to run and test microservices in isolation, and to evolve them autonomously while maintaining clear contracts between them. As long as you don’t change the interfaces or contracts, you can change the internal implementation of any microservice or add new functionality without breaking other microservices.</p>
	<p class="block_14">The following are important aspects to enable success in going into production with a microservices-based system:</p>
	<ul class="list_">
	<li class="block_25">Monitoring and health checks of the services and infrastructure.</li>
	<li class="block_25">Scalable infrastructure for the services (that is, cloud and orchestrators).</li>
	<li class="block_25">Security design and implementation at multiple levels: authentication, authorization, secrets management, secure communication, etc.</li>
	<li class="block_25">Rapid application delivery, usually with different teams focusing on different microservices.</li>
	<li class="block_25">DevOps and CI/CD practices and infrastructure.</li>
</ul>
	<p class="block_17"><span class="text_5">Of these, only the first three are covered or introduced in this guide. The last two points, which are related to application lifecycle, are covered in the additional </span><a href="https://aka.ms/dockerlifecycleebook" class="text_4">Containerized Docker Application Lifecycle with Microsoft Platform and Tools</a><span class="text_5"> e-book.</span></p>
	<h2 id="id_Toc534713543" class="block_18">Additional resources</h2>
	<ul class="list_">
	<li class="block_20"><span class="text_2">Mark Russinovich. Microservices: An application revolution powered by the cloud</span><span class="text_"><br class="calibre6"/></span><a href="https://azure.microsoft.com/blog/microservices-an-application-revolution-powered-by-the-cloud/" class="text_1">https://azure.microsoft.com/blog/microservices-an-application-revolution-powered-by-the-cloud/</a></li>
	<li class="block_20"><span class="text_2">Martin Fowler. Microservices</span><span class="text_"><br class="calibre6"/></span><a href="http://www.martinfowler.com/articles/microservices.html" class="text_1">http://www.martinfowler.com/articles/microservices.html</a></li>
	<li class="block_20"><span class="text_2">Martin Fowler. Microservice Prerequisites</span><span class="text_"><br class="calibre6"/></span><a href="http://martinfowler.com/bliki/MicroservicePrerequisites.html" class="text_1">http://martinfowler.com/bliki/MicroservicePrerequisites.html</a></li>
	<li class="block_20"><span class="text_2">Jimmy Nilsson. Chunk Cloud Computing</span><span class="text_"><br class="calibre6"/></span><a href="https://www.infoq.com/articles/CCC-Jimmy-Nilsson" class="text_1">https://www.infoq.com/articles/CCC-Jimmy-Nilsson</a></li>
	<li class="block_20"><span class="text_2">Cesar de la Torre. Containerized Docker Application Lifecycle with Microsoft Platform and Tools</span><span class="text_"> (downloadable e-book)<br class="calibre6"/></span><a href="https://aka.ms/dockerlifecycleebook" class="text_1">https://aka.ms/dockerlifecycleebook</a></li>
</ul>
	<h1 id="id_Toc534713544" class="block_24">Data sovereignty per microservice</h1>
	<p class="block_14">An important rule for microservices architecture is that each microservice must own its domain data and logic. Just as a full application owns its logic and data, so must each microservice own its logic and data under an autonomous lifecycle, with independent deployment per microservice.</p>
	<p class="block_14">This means that the conceptual model of the domain will differ between subsystems or microservices. Consider enterprise applications, where customer relationship management (CRM) applications, transactional purchase subsystems, and customer support subsystems each call on unique customer entity attributes and data, and where each employs a different Bounded Context (BC).</p>
	<p class="block_17"><span class="text_5">This principle is similar in </span><a href="https://en.wikipedia.org/wiki/Domain-driven_design" class="text_4">Domain-driven design (DDD)</a><span class="text_5">, where each </span><a href="https://martinfowler.com/bliki/BoundedContext.html" class="text_4">Bounded Context</a><span class="text_5"> or autonomous subsystem or service must own its domain model (data plus logic and behavior). Each DDD Bounded Context correlates to one business microservice (one or several services). This point about the Bounded Context pattern is expanded in the next section.</span></p>
	<p class="block_14">On the other hand, the traditional (monolithic data) approach used in many applications is to have a single centralized database or just a few databases. This is often a normalized SQL database that’s used for the whole application and all its internal subsystems, as shown in Figure 4-7.</p>
	<p class="block_14"><img src="images/image-11.png" alt="C:\Users\Miguel\source\repos\dotnet\docs\docs\standard\microservices-architecture\architect-microservice-container-applications\media\image7.png" class="calibre23"/></p>
	<p class="block_23"><span class="text_6">Figure 4-7</span><i class="calibre8">. Data sovereignty comparison: monolithic database versus microservices</i></p>
	<p class="block_14">The centralized database approach initially looks simpler and seems to enable reuse of entities in different subsystems to make everything consistent. But the reality is you end up with huge tables that serve many different subsystems, and that include attributes and columns that aren’t needed in most cases. It’s like trying to use the same physical map for hiking a short trail, taking a day-long car trip, and learning geography.</p>
	<p class="block_17"><span class="text_5">A monolithic application with typically a single relational database has two important benefits: </span><a href="https://en.wikipedia.org/wiki/ACID" class="text_4">ACID transactions</a><span class="text_5"> and the SQL language, both working across all the tables and data related to your application. This approach provides a way to easily write a query that combines data from multiple tables.</span></p>
	<p class="block_14">However, data access becomes much more complex when you move to a microservices architecture. But even when ACID transactions can or should be used within a microservice or Bounded Context, the data owned by each microservice is private to that microservice and can only be accessed via its microservice API. Encapsulating the data ensures that the microservices are loosely coupled and can evolve independently of one another. If multiple services were accessing the same data, schema updates would require coordinated updates to all the services. This would break the microservice lifecycle autonomy. But distributed data structures mean that you can’t make a single ACID transaction across microservices. This in turn means you must use eventual consistency when a business process spans multiple microservices. This is much harder to implement than simple SQL joins, because you can’t create integrity constraints or use distributed transactions between separate databases, as we’ll explain later on. Similarly, many other relational database features aren’t available across multiple microservices.</p>
	<p class="block_17"><span class="text_5">Going even further, different microservices often use different </span><span class="text_10">kinds</span><span class="text_5"> of databases. Modern applications store and process diverse kinds of data, and a relational database isn’t always the best choice. For some use cases, a NoSQL database such as Azure CosmosDB or MongoDB might have a more convenient data model and offer better performance and scalability than a SQL database like SQL Server or Azure SQL Database. In other cases, a relational database is still the best approach. Therefore, microservices-based applications often use a mixture of SQL and NoSQL databases, which is sometimes called the </span><a href="https://martinfowler.com/bliki/PolyglotPersistence.html" class="text_4">polyglot persistence</a><span class="text_5"> approach.</span></p>
	<p class="block_17"><span class="text_5">A partitioned, polyglot-persistent architecture for data storage has many benefits. These include loosely coupled services and better performance, scalability, costs, and manageability. However, it can introduce some distributed data management challenges, as explained in “</span><a href="#id_Toc534713554" class="text_4">Identifying domain-model boundaries</a><span class="text_5">” later in this chapter.</span></p>
	<h2 id="id_Toc534713545" class="block_18">The relationship between microservices and the Bounded Context pattern</h2>
	<p class="block_17"><span class="text_5">The concept of microservice derives from the </span><a href="http://martinfowler.com/bliki/BoundedContext.html" class="text_4">Bounded Context (BC) pattern</a><span class="text_5"> in </span><a href="https://en.wikipedia.org/wiki/Domain-driven_design" class="text_4">domain-driven design (DDD)</a><span class="text_5">. DDD deals with large models by dividing them into multiple BCs and being explicit about their boundaries. Each BC must have its own model and database; likewise, each microservice owns its related data. In addition, each BC usually has its own </span><a href="http://martinfowler.com/bliki/UbiquitousLanguage.html" class="text_4">ubiquitous language</a><span class="text_5"> to help communication between software developers and domain experts.</span></p>
	<p class="block_14">Those terms (mainly domain entities) in the ubiquitous language can have different names in different Bounded Contexts, even when different domain entities share the same identity (that is, the unique ID that’s used to read the entity from storage). For instance, in a user-profile Bounded Context, the User domain entity might share identity with the Buyer domain entity in the ordering Bounded Context.</p>
	<p class="block_17"><span class="text_5">A microservice is therefore like a Bounded Context, but it also specifies that it’s a distributed service. It’s built as a separate process for each Bounded Context, and it must use the distributed protocols noted earlier, like HTTP/HTTPS, WebSockets, or </span><a href="https://en.wikipedia.org/wiki/Advanced_Message_Queuing_Protocol" class="text_4">AMQP</a><span class="text_5">. The Bounded Context pattern, however, doesn’t specify whether the Bounded Context is a distributed service or if it’s simply a logical boundary (such as a generic subsystem) within a monolithic-deployment application.</span></p>
	<p class="block_14">It’s important to highlight that defining a service for each Bounded Context is a good place to start. But you don’t have to constrain your design to it. Sometimes you must design a Bounded Context or business microservice composed of several physical services. But ultimately, both patterns -Bounded Context and microservice- are closely related.</p>
	<p class="block_14">DDD benefits from microservices by getting real boundaries in the form of distributed microservices. But ideas like not sharing the model between microservices are what you also want in a Bounded Context.</p>
	<h3 id="id_Toc534713546" class="block_19">Additional resources</h3>
	<ul class="list_">
	<li class="block_20"><span class="text_2">Chris Richardson. Pattern: Database per service</span><span class="text_"><br class="calibre6"/></span><a href="https://microservices.io/patterns/data/database-per-service.html" class="text_1">https://microservices.io/patterns/data/database-per-service.html</a></li>
	<li class="block_20"><span class="text_2">Martin Fowler. BoundedContext</span><span class="text_"><br class="calibre6"/></span><a href="https://martinfowler.com/bliki/BoundedContext.html" class="text_1">https://martinfowler.com/bliki/BoundedContext.html</a></li>
	<li class="block_20"><span class="text_2">Martin Fowler. PolyglotPersistence</span><span class="text_"><br class="calibre6"/></span><a href="https://martinfowler.com/bliki/PolyglotPersistence.html" class="text_1">https://martinfowler.com/bliki/PolyglotPersistence.html</a></li>
	<li class="block_20"><span class="text_2">Alberto Brandolini. Strategic Domain Driven Design with Context Mapping</span><span class="text_"><br class="calibre6"/></span><a href="https://www.infoq.com/articles/ddd-contextmapping" class="text_1">https://www.infoq.com/articles/ddd-contextmapping</a></li>
</ul>
	<h1 id="id_Toc534713547" class="block_24">Logical architecture versus physical architecture</h1>
	<p class="block_14">It’s useful at this point to stop and discuss the distinction between logical architecture and physical architecture, and how this applies to the design of microservice-based applications.</p>
	<p class="block_14">To begin, building microservices doesn’t require the use of any specific technology. For instance, Docker containers aren’t mandatory to create a microservice-based architecture. Those microservices could also be run as plain processes. Microservices is a logical architecture.</p>
	<p class="block_17"><span class="text_5">Moreover, even when a microservice could be physically implemented as a single service, process, or container (for simplicity’s sake, that’s the approach taken in the initial version of </span><a href="https://aka.ms/MicroservicesArchitecture" class="text_4">eShopOnContainers</a><span class="text_5">), this parity between business microservice and physical service or container isn’t necessarily required in all cases when you build a large and complex application composed of many dozens or even hundreds of services.</span></p>
	<p class="block_14">This is where there’s a difference between an application’s logical architecture and physical architecture. The logical architecture and logical boundaries of a system do not necessarily map one-to-one to the physical or deployment architecture. It can happen, but it often doesn’t.</p>
	<p class="block_14">Although you might have identified certain business microservices or Bounded Contexts, it doesn’t mean that the best way to implement them is always by creating a single service (such as an ASP.NET Web API) or single Docker container for each business microservice. Having a rule saying each business microservice has to be implemented using a single service or container is too rigid.</p>
	<p class="block_14">Therefore, a business microservice or Bounded Context is a logical architecture that might coincide (or not) with physical architecture. The important point is that a business microservice or Bounded Context must be autonomous by allowing code and state to be independently versioned, deployed, and scaled.</p>
	<p class="block_14">As Figure 4-8 shows, the catalog business microservice could be composed of several services or processes. These could be multiple ASP.NET Web API services or any other kind of services using HTTP or any other protocol. More importantly, the services could share the same data, as long as these services are cohesive with respect to the same business domain.</p>
	<p class="block_14"><img src="images/image-12.png" alt="C:\Users\Miguel\source\repos\dotnet\docs\docs\standard\microservices-architecture\architect-microservice-container-applications\media\image8.png" class="calibre24"/></p>
	<p class="block_23"><span class="text_6">Figure 4-8</span><i class="calibre8">. Business microservice with several physical services</i></p>
	<p class="block_14">The services in the example share the same data model because the Web API service targets the same data as the Search service. So, in the physical implementation of the business microservice, you’re splitting that functionality so you can scale each of those internal services up or down as needed. Maybe the Web API service usually needs more instances than the Search service, or vice versa.</p>
	<p class="block_14">In short, the logical architecture of microservices doesn’t always have to coincide with the physical deployment architecture. In this guide, whenever we mention a microservice, we mean a business or logical microservice that could map to one or more (physical) services. In most cases, this will be a single service, but it might be more.</p>
	<h1 id="id_Toc534713548" class="block_24">Challenges and solutions for distributed data management</h1>
	<h2 id="id_Toc534713549" class="block_18">Challenge #1: How to define the boundaries of each microservice</h2>
	<p class="block_14">Defining microservice boundaries is probably the first challenge anyone encounters. Each microservice has to be a piece of your application and each microservice should be autonomous with all the benefits and challenges that it conveys. But how do you identify those boundaries?</p>
	<p class="block_14">First, you need to focus on the application’s logical domain models and related data. Try to identify decoupled islands of data and different contexts within the same application. Each context could have a different business language (different business terms). The contexts should be defined and managed independently. The terms and entities that are used in those different contexts might sound similar, but you might discover that in a particular context, a business concept with one is used for a different purpose in another context, and might even have a different name. For instance, a user can be referred as a user in the identity or membership context, as a customer in a CRM context, as a buyer in an ordering context, and so forth.</p>
	<p class="block_17"><span class="text_5">The way you identify boundaries between multiple application contexts with a different domain for each context is exactly how you can identify the boundaries for each business microservice and its related domain model and data. You always attempt to minimize the coupling between those microservices. This guide goes into more detail about this identification and domain model design in the section </span><a href="#id_Toc534713554" class="text_4">Identifying domain-model boundaries for each microservice</a><span class="text_5"> later.</span></p>
	<h2 id="id_Toc534713550" class="block_18">Challenge #2: How to create queries that retrieve data from several microservices</h2>
	<p class="block_14">A second challenge is how to implement queries that retrieve data from several microservices, while avoiding chatty communication to the microservices from remote client apps. An example could be a single screen from a mobile app that needs to show user information that’s owned by the basket, catalog, and user identity microservices. Another example would be a complex report involving many tables located in multiple microservices. The right solution depends on the complexity of the queries. But in any case, you’ll need a way to aggregate information if you want to improve the efficiency in the communications of your system. The most popular solutions are the following.</p>
	<p class="block_17"><span class="text_7">API Gateway.</span><span class="text_5"> For simple data aggregation from multiple microservices that own different databases, the recommended approach is an aggregation microservice referred to as an API Gateway. However, you need to be careful about implementing this pattern, because it can be a choke point in your system, and it can violate the principle of microservice autonomy. To mitigate this possibility, you can have multiple fined-grained API Gateways each one focusing on a vertical “slice” or business area of the system. The API Gateway pattern is explained in more detail in the </span><a href="#id_Toc534713557" class="text_4">API Gateway section</a><span class="text_5"> later.</span></p>
	<p class="block_17"><span class="text_7">CQRS with query/reads tables.</span><span class="text_5"> Another solution for aggregating data from multiple microservices is the </span><a href="https://docs.microsoft.com/azure/architecture/patterns/materialized-view" class="text_4">Materialized View pattern</a><span class="text_5">. In this approach, you generate, in advance (prepare denormalized data before the actual queries happen), a read-only table with the data that’s owned by multiple microservices. The table has a format suited to the client app’s needs.</span></p>
	<p class="block_14">Consider something like the screen for a mobile app. If you have a single database, you might pull together the data for that screen using a SQL query that performs a complex join involving multiple tables. However, when you have multiple databases, and each database is owned by a different microservice, you cannot query those databases and create a SQL join. Your complex query becomes a challenge. You can address the requirement using a CQRS approach—you create a denormalized table in a different database that’s used just for queries. The table can be designed specifically for the data you need for the complex query, with a one-to-one relationship between fields needed by your application’s screen and the columns in the query table. It could also serve for reporting purposes.</p>
	<p class="block_17"><span class="text_5">This approach not only solves the original problem (how to query and join across microservices), but it also improves performance considerably when compared with a complex join, because you already have the data that the application needs in the query table. Of course, using Command and Query Responsibility Segregation (CQRS) with query/reads tables means additional development work, and you’ll need to embrace eventual consistency. Nonetheless, requirements on performance and high scalability in </span><a href="http://udidahan.com/2011/10/02/why-you-should-be-using-cqrs-almost-everywhere/" class="text_4">collaborative scenarios</a><span class="text_5"> (or competitive scenarios, depending on the point of view) are where you should apply CQRS with multiple databases.</span></p>
	<p class="block_14"><b class="calibre5">“Cold data” in central databases.</b> For complex reports and queries that might not require real-time data, a common approach is to export your “hot data” (transactional data from the microservices) as “cold data” into large databases that are used only for reporting. That central database system can be a Big Data-based system, like Hadoop, a data warehouse like one based on Azure SQL Data Warehouse, or even a single SQL database that’s used just for reports (if size won’t be an issue).</p>
	<p class="block_14">Keep in mind that this centralized database would be used only for queries and reports that do not need real-time data. The original updates and transactions, as your source of truth, have to be in your microservices data. The way you would synchronize data would be either by using event-driven communication (covered in the next sections) or by using other database infrastructure import/export tools. If you use event-driven communication, that integration process would be similar to the way you propagate data as described earlier for CQRS query tables.</p>
	<p class="block_14">However, if your application design involves constantly aggregating information from multiple microservices for complex queries, it might be a symptom of a bad design -a microservice should be as isolated as possible from other microservices. (This excludes reports/analytics that always should use cold-data central databases.) Having this problem often might be a reason to merge microservices. You need to balance the autonomy of evolution and deployment of each microservice with strong dependencies, cohesion, and data aggregation.</p>
	<h2 id="id_Toc534713551" class="block_18">Challenge #3: How to achieve consistency across multiple microservices</h2>
	<p class="block_14">As stated previously, the data owned by each microservice is private to that microservice and can only be accessed using its microservice API. Therefore, a challenge presented is how to implement end-to-end business processes while keeping consistency across multiple microservices.</p>
	<p class="block_17"><span class="text_5">To analyze this problem, let’s look at an example from the </span><a href="https://aka.ms/eshoponcontainers" class="text_4">eShopOnContainers reference application</a><span class="text_5">. The Catalog microservice maintains information about all the products, including the product price. The Basket microservice manages temporal data about product items that users are adding to their shopping baskets, which includes the price of the items at the time they were added to the basket. When a product’s price is updated in the catalog, that price should also be updated in the active baskets that hold that same product, plus the system should probably warn the user saying that a particular item’s price has changed since they added it to their basket.</span></p>
	<p class="block_14">In a hypothetical monolithic version of this application, when the price changes in the products table, the catalog subsystem could simply use an ACID transaction to update the current price in the Basket table.</p>
	<p class="block_14">However, in a microservices-based application, the Product and Basket tables are owned by their respective microservices. No microservice should ever include tables/storage owned by another microservice in its own transactions, not even in direct queries, as shown in Figure 4-9.</p>
	<p class="block_14"><img src="images/image-13.png" alt="C:\Users\Miguel\source\repos\dotnet\docs\docs\standard\microservices-architecture\architect-microservice-container-applications\media\image9.png" class="calibre25"/></p>
	<p class="block_23"><span class="text_6">Figure 4-9</span><i class="calibre8">. A microservice can’t directly access a table in another microservice</i></p>
	<p class="block_17"><span class="text_5">The Catalog microservice shouldn’t update the Basket table directly, because the Basket table is owned by the Basket microservice. To make an update to the Basket microservice, the Catalog microservice should use eventual consistency probably based on asynchronous communication such as integration events (message and event-based communication). This is how the </span><a href="http://aka.ms/eshoponcontainers" class="text_4">eShopOnContainers</a><span class="text_5"> reference application performs this type of consistency across microservices.</span></p>
	<p class="block_17"><span class="text_5">As stated by the </span><a href="https://en.wikipedia.org/wiki/CAP_theorem" class="text_4">CAP theorem</a><span class="text_5">, you need to choose between availability and ACID strong consistency. Most microservice-based scenarios demand availability and high scalability as opposed to strong consistency. Mission-critical applications must remain up and running, and developers can work around strong consistency by using techniques for working with weak or eventual consistency. This is the approach taken by most microservice-based architectures.</span></p>
	<p class="block_14">Moreover, ACID-style or two-phase commit transactions are not just against microservices principles; most NoSQL databases (like Azure Cosmos DB, MongoDB, etc.) do not support two-phase commit transactions, typical in distributed databases scenarios. However, maintaining data consistency across services and databases is essential. This challenge is also related to the question of how to propagate changes across multiple microservices when certain data needs to be redundant—for example, when you need to have the product’s name or description in the Catalog microservice and the Basket microservice.</p>
	<p class="block_17"><span class="text_5">A good solution for this problem is to use eventual consistency between microservices articulated through event-driven communication and a publish-and-subscribe system. These topics are covered in the section </span><a href="#id_Toc534713575" class="text_4">Asynchronous event-driven communication</a><span class="text_5"> later in this guide.</span></p>
	<h2 id="id_Toc534713552" class="block_18">Challenge #4: How to design communication across microservice boundaries</h2>
	<p class="block_14">Communicating across microservice boundaries is a real challenge. In this context, communication doesn’t refer to what protocol you should use (HTTP and REST, AMQP, messaging, and so on). Instead, it addresses what communication style you should use, and especially how coupled your microservices should be. Depending on the level of coupling, when failure occurs, the impact of that failure on your system will vary significantly.</p>
	<p class="block_14">In a distributed system like a microservices-based application, with so many artifacts moving around and with distributed services across many servers or hosts, components will eventually fail. Partial failure and even larger outages will occur, so you need to design your microservices and the communication across them considering the common risks in this type of distributed system.</p>
	<p class="block_14">A popular approach is to implement HTTP (REST)-based microservices, due to their simplicity. An HTTP-based approach is perfectly acceptable; the issue here is related to how you use it. If you use HTTP requests and responses just to interact with your microservices from client applications or from API Gateways, that’s fine. But if you create long chains of synchronous HTTP calls across microservices, communicating across their boundaries as if the microservices were objects in a monolithic application, your application will eventually run into problems.</p>
	<p class="block_14">For instance, imagine that your client application makes an HTTP API call to an individual microservice like the Ordering microservice. If the Ordering microservice in turn calls additional microservices using HTTP within the same request/response cycle, you’re creating a chain of HTTP calls. It might sound reasonable initially. However, there are important points to consider when going down this path:</p>
	<ul class="list_">
	<li class="block_25">Blocking and low performance. Due to the synchronous nature of HTTP, the original request doesn’t get a response until all the internal HTTP calls are finished. Imagine if the number of these calls increases significantly and at the same time one of the intermediate HTTP calls to a microservice is blocked. The result is that performance is impacted, and the overall scalability will be exponentially affected as additional HTTP requests increase.</li>
	<li class="block_25">Coupling microservices with HTTP. Business microservices shouldn’t be coupled with other business microservices. Ideally, they shouldn’t “know” about the existence of other microservices. If your application relies on coupling microservices as in the example, achieving autonomy per microservice will be almost impossible.</li>
	<li class="block_25">Failure in any one microservice. If you implemented a chain of microservices linked by HTTP calls, when any of the microservices fails (and eventually they will fail) the whole chain of microservices will fail. A microservice-based system should be designed to continue to work as well as possible during partial failures. Even if you implement client logic that uses retries with exponential backoff or circuit breaker mechanisms, the more complex the HTTP call chains are, the more complex it is to implement a failure strategy based on HTTP.</li>
</ul>
	<p class="block_14">In fact, if your internal microservices are communicating by creating chains of HTTP requests as described, it could be argued that you have a monolithic application, but one based on HTTP between processes instead of intra-process communication mechanisms.</p>
	<p class="block_14">Therefore, in order to enforce microservice autonomy and have better resiliency, you should minimize the use of chains of request/response communication across microservices. It’s recommended that you use only asynchronous interaction for inter-microservice communication, either by using asynchronous message- and event-based communication, or by using (asynchronous) HTTP polling independently of the original HTTP request/response cycle.</p>
	<p class="block_17"><span class="text_5">The use of asynchronous communication is explained with additional details later in this guide in the sections </span><a href="#id_Toc534713567" class="text_4">Asynchronous microservice integration enforces microservice’s autonomy</a><span class="text_5"> and </span><a href="#id_Toc534713572" class="text_4">Asynchronous message-based communication</a><span class="text_5">.</span></p>
	<h2 id="id_Toc534713553" class="block_18">Additional resources</h2>
	<ul class="list_">
	<li class="block_20"><span class="text_2">CAP theorem</span><span class="text_"><br class="calibre6"/></span><a href="https://en.wikipedia.org/wiki/CAP_theorem" class="text_1">https://en.wikipedia.org/wiki/CAP_theorem</a></li>
	<li class="block_20"><span class="text_2">Eventual consistency</span><span class="text_"><br class="calibre6"/></span><a href="https://en.wikipedia.org/wiki/Eventual_consistency" class="text_1">https://en.wikipedia.org/wiki/Eventual_consistency</a></li>
	<li class="block_20"><span class="text_2">Data Consistency Primer</span><span class="text_"><br class="calibre6"/></span><a href="https://docs.microsoft.com/previous-versions/msp-n-p/dn589800(v=pandp.10)" class="text_1">https://docs.microsoft.com/previous-versions/msp-n-p/dn589800(v=pandp.10)</a></li>
	<li class="block_20"><span class="text_2">Martin Fowler. CQRS (Command and Query Responsibility Segregation)</span><span class="text_"><br class="calibre6"/></span><a href="https://martinfowler.com/bliki/CQRS.html" class="text_1">https://martinfowler.com/bliki/CQRS.html</a></li>
	<li class="block_20"><span class="text_2">Materialized View</span><span class="text_"><br class="calibre6"/></span><a href="https://docs.microsoft.com/azure/architecture/patterns/materialized-view" class="text_1">https://docs.microsoft.com/azure/architecture/patterns/materialized-view</a></li>
	<li class="block_20"><span class="text_2">Charles Row. ACID vs. BASE: The Shifting pH of Database Transaction Processing</span><span class="text_"><br class="calibre6"/></span><a href="http://www.dataversity.net/acid-vs-base-the-shifting-ph-of-database-transaction-processing/" class="text_1">http://www.dataversity.net/acid-vs-base-the-shifting-ph-of-database-transaction-processing/</a></li>
	<li class="block_20"><span class="text_2">Compensating Transaction</span><span class="text_"><br class="calibre6"/></span><a href="https://docs.microsoft.com/azure/architecture/patterns/compensating-transaction" class="text_1">https://docs.microsoft.com/azure/architecture/patterns/compensating-transaction</a></li>
	<li class="block_20"><span class="text_2">Udi Dahan. Service Oriented Composition</span><span class="text_"><br class="calibre6"/></span><a href="http://udidahan.com/2014/07/30/service-oriented-composition-with-video/" class="text_1">http://udidahan.com/2014/07/30/service-oriented-composition-with-video/</a></li>
</ul>
	<h1 id="id_Toc534713554" class="block_24">Identify domain-model boundaries for each microservice</h1>
	<p class="block_14">The goal when identifying model boundaries and size for each microservice isn’t to get to the most granular separation possible, although you should tend toward small microservices if possible. Instead, your goal should be to get to the most meaningful separation guided by your domain knowledge. The emphasis isn’t on the size, but instead on business capabilities. In addition, if there’s clear cohesion needed for a certain area of the application based on a high number of dependencies, that indicates the need for a single microservice, too. Cohesion is a way to identify how to break apart or group together microservices. Ultimately, while you gain more knowledge about the domain, you should adapt the size of your microservice, iteratively. Finding the right size isn’t a one-shot process.</p>
	<p class="block_17"><a href="https://samnewman.io/" class="text_4">Sam Newman</a><span class="text_5">, a recognized promoter of microservices and author of the book </span><a href="https://samnewman.io/books/building_microservices/" class="text_4">Building Microservices</a><span class="text_5">, highlights that you should design your microservices based on the Bounded Context (BC) pattern (part of domain-driven design), as introduced earlier. Sometimes, a BC could be composed of several physical services, but not vice versa.</span></p>
	<p class="block_14">A domain model with specific domain entities applies within a concrete BC or microservice. A BC delimits the applicability of a domain model and gives developer team members a clear and shared understanding of what must be cohesive and what can be developed independently. These are the same goals for microservices.</p>
	<p class="block_17"><span class="text_5">Another tool that informs your design choice is </span><a href="https://en.wikipedia.org/wiki/Conway%27s_law" class="text_4">Conway’s law</a><span class="text_5">, which states that an application will reflect the social boundaries of the organization that produced it. But sometimes the opposite is true -the company’s organization is formed by the software. You might need to reverse Conway’s law and build the boundaries the way you want the company to be organized, leaning toward business process consulting.</span></p>
	<p class="block_17"><span class="text_5">To identify bounded contexts, you can use a DDD pattern called the </span><a href="https://www.infoq.com/articles/ddd-contextmapping" class="text_4">Context Mapping pattern</a><span class="text_5">. With Context Mapping, you identify the various contexts in the application and their boundaries. It’s common to have a different context and boundary for each small subsystem, for instance. The Context Map is a way to define and make explicit those boundaries between domains. A BC is autonomous and includes the details of a single domain -details like the domain entities- and defines integration contracts with other BCs. This is similar to the definition of a microservice: it’s autonomous, it implements certain domain capability, and it must provide interfaces. This is why Context Mapping and the Bounded Context pattern are good approaches for identifying the domain model boundaries of your microservices.</span></p>
	<p class="block_14">When designing a large application, you’ll see how its domain model can be fragmented - a domain expert from the catalog domain will name entities differently in the catalog and inventory domains than a shipping domain expert, for instance. Or the user domain entity might be different in size and number of attributes when dealing with a CRM expert who wants to store every detail about the customer than for an ordering domain expert who just needs partial data about the customer. It’s very hard to disambiguate all domain terms across all the domains related to a large application. But the most important thing is that you shouldn’t try to unify the terms. Instead, accept the differences and richness provided by each domain. If you try to have a unified database for the whole application, attempts at a unified vocabulary will be awkward and won’t sound right to any of the multiple domain experts. Therefore, BCs (implemented as microservices) will help you to clarify where you can use certain domain terms and where you’ll need to split the system and create additional BCs with different domains.</p>
	<p class="block_14">You’ll know that you got the right boundaries and sizes of each BC and domain model if you have few strong relationships between domain models, and you do not usually need to merge information from multiple domain models when performing typical application operations.</p>
	<p class="block_14">Perhaps the best answer to the question of how large a domain model for each microservice should be is the following: it should have an autonomous BC, as isolated as possible, that enables you to work without having to constantly switch to other contexts (other microservice’s models). In Figure 4-10, you can see how multiple microservices (multiple BCs) each has their own model and how their entities can be defined, depending on the specific requirements for each of the identified domains in your application.</p>
	<p class="block_14"><img src="images/image-14.png" alt="C:\Users\Miguel\source\repos\dotnet\docs\docs\standard\microservices-architecture\architect-microservice-container-applications\media\image10.png" class="calibre26"/></p>
	<p class="block_23"><span class="text_6">Figure 4-10</span><i class="calibre8">. Identifying entities and microservice model boundaries</i></p>
	<p class="block_14">Figure 4-10 illustrates a sample scenario related to an online conference management system. You’ve identified several BCs that could be implemented as microservices, based on domains that domain experts defined for you. As you can see, there are entities that are present just in a single microservice model, like Payments in the Payment microservice. Those will be easy to implement.</p>
	<p class="block_17"><span class="text_5">However, you might also have entities that have a different shape but share the same identity across the multiple domain models from the multiple microservices. For example, the User entity is identified in the Conferences Management microservice. That same user, with the same identity, is the one named Buyers in the Ordering microservice, or the one named Payer in the Payment microservice, and even the one named Customer in the Customer Service microservice. This is because, depending on the </span><a href="https://martinfowler.com/bliki/UbiquitousLanguage.html" class="text_4">ubiquitous language</a><span class="text_5"> that each domain expert is using, a user might have a different perspective even with different attributes. The user entity in the microservice model named Conferences Management might have most of its personal data attributes. However, that same user in the shape of Payer in the microservice Payment or in the shape of Customer in the microservice Customer Service might not need the same list of attributes.</span></p>
	<p class="block_14">A similar approach is illustrated in Figure 4-11.</p>
	<p class="block_14"><img src="images/image-15.png" alt="C:\Users\Miguel\source\repos\dotnet\docs\docs\standard\microservices-architecture\architect-microservice-container-applications\media\image11.png" class="calibre27"/></p>
	<p class="block_23"><span class="text_6">Figure 4-11</span><i class="calibre8">. Decomposing traditional data models into multiple domain models</i></p>
	<p class="block_14">You can see how the user is present in the Conferences Management microservice model as the User entity and is also present in the form of the Buyer entity in the Pricing microservice, with alternate attributes or details about the user when it’s actually a buyer. Each microservice or BC might not need all the data related to a User entity, just part of it, depending on the problem to solve or the context. For instance, in the Pricing microservice model, you do not need the address or the name of the user, just the ID (as identity) and Status, which will have an impact on discounts when pricing the seats per buyer.</p>
	<p class="block_14">The Seat entity has the same name but different attributes in each domain model. However, Seat shares identity based on the same ID, as happens with User and Buyer.</p>
	<p class="block_14">Basically, there’s a shared concept of a user that exists in multiple services (domains), which all share the identity of that user. But in each domain model there might be additional or different details about the user entity. Therefore, there needs to be a way to map a user entity from one domain (microservice) to another.</p>
	<p class="block_14">There are several benefits to not sharing the same user entity with the same number of attributes across domains. One benefit is to reduce duplication, so that microservice models do not have any data that they do not need. Another benefit is having a master microservice that owns a certain type of data per entity so that updates and queries for that type of data are driven only by that microservice.</p>
	<h1 id="id_Toc534713555" class="block_24">The API gateway pattern versus the Direct client-to-microservice communication</h1>
	<p class="block_14">In a microservices architecture, each microservice exposes a set of (typically) fine-grained endpoints. This fact can impact the client-to-microservice communication, as explained in this section.</p>
	<h2 id="id_Toc534713556" class="block_18">Direct client-to-microservice communication</h2>
	<p class="block_14">A possible approach is to use a direct client-to-microservice communication architecture. In this approach, a client app can make requests directly to some of the microservices, as shown in Figure 4-12.</p>
	<p class="block_14"><img src="images/image-16.png" alt="C:\Users\Miguel\source\repos\dotnet\docs\docs\standard\microservices-architecture\architect-microservice-container-applications\media\image12.png" class="calibre28"/></p>
	<p class="block_23"><span class="text_6">Figure 4-12</span><i class="calibre8">. Using a direct client-to-microservice communication architecture</i></p>
	<p class="block_14">In this approach, each microservice has a public endpoint, sometimes with a different TCP port for each microservice. An example of a URL for a particular service could be the following URL in Azure:</p>
	<p class="block_17"><a href="http://eshoponcontainers.westus.cloudapp.azure.com:88/" class="text_4">http://eshoponcontainers.westus.cloudapp.azure.com:88/</a></p>
	<p class="block_17"><span class="text_5">In a production environment based on a cluster, that URL would map to the load balancer used in the cluster, which in turn distributes the requests across the microservices. In production environments, you could have an Application Delivery Controller (ADC) like </span><a href="https://docs.microsoft.com/azure/application-gateway/application-gateway-introduction" class="text_4">Azure Application Gateway</a><span class="text_5"> between your microservices and the Internet. This acts as a transparent tier that not only performs load balancing, but secures your services by offering SSL termination. This improves the load of your hosts by offloading CPU-intensive SSL termination and other routing duties to the Azure Application Gateway. In any case, a load balancer and ADC are transparent from a logical application architecture point of view.</span></p>
	<p class="block_14">A direct client-to-microservice communication architecture could be good enough for a small microservice-based application, especially if the client app is a server-side web application like an ASP.NET MVC app. However, when you build large and complex microservice-based applications (for example, when handling dozens of microservice types), and especially when the client apps are remote mobile apps or SPA web applications, that approach faces a few issues.</p>
	<p class="block_14">Consider the following questions when developing a large application based on microservices:</p>
	<ul class="list_">
	<li class="block_25"><i class="calibre8">How can client apps minimize the number of requests to the back end and reduce chatty communication to multiple microservices?</i></li>
</ul>
	<p class="block_14">Interacting with multiple microservices to build a single UI screen increases the number of round trips across the Internet. This increases latency and complexity on the UI side. Ideally, responses should be efficiently aggregated in the server side. This reduces latency, since multiple pieces of data come back in parallel and some UI can show data as soon as it’s ready.</p>
	<ul class="list_">
	<li class="block_25"><i class="calibre8">How can you handle cross-cutting concerns such as authorization, data transformations, and dynamic request dispatching?</i></li>
</ul>
	<p class="block_14">Implementing security and cross-cutting concerns like security and authorization on every microservice can require significant development effort. A possible approach is to have those services within the Docker host or internal cluster to restrict direct access to them from the outside, and to implement those cross-cutting concerns in a centralized place, like an API Gateway.</p>
	<ul class="list_">
	<li class="block_25">How can client apps communicate with services that use non-Internet-friendly protocols?*</li>
</ul>
	<p class="block_14">Protocols used on the server side (like AMQP or binary protocols) are usually not supported in client apps. Therefore, requests must be performed through protocols like HTTP/HTTPS and translated to the other protocols afterwards. A <i class="calibre15">man-in-the-middle</i> approach can help in this situation.</p>
	<ul class="list_">
	<li class="block_25"><i class="calibre8">How can you shape a facade especially made for mobile apps?</i></li>
</ul>
	<p class="block_14">The API of multiple microservices might not be well designed for the needs of different client applications. For instance, the needs of a mobile app might be different than the needs of a web app. For mobile apps, you might need to optimize even further so that data responses can be more efficient. You might do this by aggregating data from multiple microservices and returning a single set of data, and sometimes eliminating any data in the response that isn’t needed by the mobile app. And, of course, you might compress that data. Again, a facade or API in between the mobile app and the microservices can be convenient for this scenario.</p>
	<h2 id="id_Toc534713557" class="block_18">Why consider API Gateways instead of direct client-to-microservice communication</h2>
	<p class="block_14">In a microservices architecture, the client apps usually need to consume functionality from more than one microservice. If that consumption is performed directly, the client needs to handle multiple calls to microservice endpoints. What happens when the application evolves and new microservices are introduced or existing microservices are updated? If your application has many microservices, handling so many endpoints from the client apps can be a nightmare. Since the client app would be coupled to those internal endpoints, evolving the microservices in the future can cause high impact for the client apps.</p>
	<p class="block_14">Therefore, having an intermediate level or tier of indirection (Gateway) can be very convenient for microservice-based applications. If you don’t have API Gateways, the client apps must send requests directly to the microservices and that raises problems, such as the following issues:</p>
	<ul class="list_">
	<li class="block_25"><b class="calibre1">Coupling</b>: Without the API Gateway pattern, the client apps are coupled to the internal microservices. The client apps need to know how the multiple areas of the application are decomposed in microservices. When evolving and refactoring the internal microservices, those actions impact maintenance pretty badly because they cause breaking changes to the client apps due to the direct reference to the internal microservices from the client apps. Client apps need to be updated frequently, making the solution harder to evolve.</li>
	<li class="block_25"><b class="calibre1">Too many round trips</b>: A single page/screen in the client app might require several calls to multiple services. That can result in multiple network round trips between the client and the server, adding significant latency. Aggregation handled in an intermediate level could improve the performance and user experience for the client app.</li>
	<li class="block_25"><b class="calibre1">Security issues</b>: Without a gateway, all the microservices must be exposed to the “external world”, making the attack surface larger than if you hide internal microservices that aren’t directly used by the client apps. The smaller the attack surface is, the more secure your application can be.</li>
	<li class="block_25"><b class="calibre1">Cross-cutting concerns</b>: Each publicly published microservice must handle concerns such as authorization, SSL, etc. In many situations, those concerns could be handled in a single tier so the internal microservices are simplified.</li>
</ul>
	<h2 id="id_Toc534713558" class="block_18">What is the API Gateway pattern?</h2>
	<p class="block_17"><span class="text_5">When you design and build large or complex microservice-based applications with multiple client apps, a good approach to consider can be an </span><a href="https://microservices.io/patterns/apigateway.html" class="text_4">API Gateway</a><span class="text_5">. This is a service that provides a single-entry point for certain groups of microservices. It’s similar to the </span><a href="https://en.wikipedia.org/wiki/Facade_pattern" class="text_4">Facade pattern</a><span class="text_5"> from object-oriented design, but in this case, it’s part of a distributed system. The API Gateway pattern is also sometimes known as the “backend for frontend” (</span><a href="https://samnewman.io/patterns/architectural/bff/" class="text_4">BFF</a><span class="text_5">) because you build it while thinking about the needs of the client app.</span></p>
	<p class="block_14">Therefore, the API gateway sits between the client apps and the microservices. It acts as a reverse proxy, routing requests from clients to services. It can also provide additional cross-cutting features such as authentication, SSL termination, and cache.</p>
	<p class="block_14">Figure 4-13 shows how a custom API Gateway can fit into a simplified microservice-based architecture with just a few microservices.</p>
	<p class="block_14"><img src="images/image-17.png" alt="C:\Users\Miguel\source\repos\dotnet\docs\docs\standard\microservices-architecture\architect-microservice-container-applications\media\image13.png" class="calibre29"/></p>
	<p class="block_23"><span class="text_6">Figure 4-13</span><i class="calibre8">. Using an API Gateway implemented as a custom service</i></p>
	<p class="block_14">In this example, the API Gateway would be implemented as a custom ASP.NET Core WebHost service running as a container.</p>
	<p class="block_14">It’s important to highlight that in that diagram, you would be using a single custom API Gateway service facing multiple and different client apps. That fact can be an important risk because your API Gateway service will be growing and evolving based on many different requirements from the client apps. Eventually, it will be bloated because of those different needs and effectively it could be pretty similar to a monolithic application or monolithic service. That’s why it’s very much recommended to split the API Gateway in multiple services or multiple smaller API Gateways, one per client app form-factor type, for instance.</p>
	<p class="block_14">You need to be careful when implementing the API Gateway pattern. Usually it isn’t a good idea to have a single API Gateway aggregating all the internal microservices of your application. If it does, it acts as a monolithic aggregator or orchestrator and violates microservice autonomy by coupling all the microservices.</p>
	<p class="block_14">Therefore, the API Gateways should be segregated based on business boundaries and the client apps and not act as a single aggregator for all the internal microservices.</p>
	<p class="block_17"><span class="text_5">When splitting the API Gateway tier into multiple API Gateways, if your application has multiple client apps, that can be a primary pivot when identifying the multiple API Gateways types, so that you can have a different facade for the needs of each client app. This case is a pattern named “Backend for Frontend” (</span><a href="https://samnewman.io/patterns/architectural/bff/" class="text_4">BFF</a><span class="text_5">) where each API Gateway can provide a different API tailored for each client app type, possibly even based on the client form factor by implementing specific adapter code which underneath calls multiple internal microservices, as shown in the following image:</span></p>
	<p class="block_14"><img src="images/image-18.png" alt="C:\Users\Miguel\source\repos\dotnet\docs\docs\standard\microservices-architecture\architect-microservice-container-applications\media\image13.1.png" class="calibre26"/></p>
	<p class="block_23"><span class="text_6">Figure 4-13.1</span><i class="calibre8">. Using multiple custom API Gateways</i></p>
	<p class="block_17"><span class="text_5">The previous image shows a simplified architecture with multiple fine-grained API Gateways. In this case, the boundaries identified for each API Gateway are based purely on the “Backend for Frontend” (</span><a href="https://samnewman.io/patterns/architectural/bff/" class="text_4">BFF</a><span class="text_5">) pattern, hence based just on the API needed per client app. But in larger applications you should also go further and create additional API Gateways based on business boundaries as a second design pivot.</span></p>
	<h2 id="id_Toc534713559" class="block_18">Main features in the API Gateway pattern</h2>
	<p class="block_14">An API Gateway can offer multiple features. Depending on the product it might offer richer or simpler features, however, the most important and foundational features for any API Gateway are the following design patterns:</p>
	<p class="block_14"><b class="calibre5">Reverse proxy or gateway routing.</b> The API Gateway offers a reverse proxy to redirect or route requests (layer 7 routing, usually HTTP requests) to the endpoints of the internal microservices. The gateway provides a single endpoint or URL for the client apps and then internally maps the requests to a group of internal microservices. This routing feature helps to decouple the client apps from the microservices but it’s also pretty convenient when modernizing a monolithic API by sitting the API Gateway in between the monolithic API and the client apps, then you can add new APIs as new microservices while still using the legacy monolithic API until it’s split into many microservices in the future. Because of the API Gateway, the client apps won’t notice if the APIs being used are implemented as internal microservices or a monolithic API and more importantly, when evolving and refactoring the monolithic API into microservices, thanks to the API Gateway routing, client apps won’t be impacted with any URI change.</p>
	<p class="block_17"><span class="text_5">For more information, see </span><a href="https://docs.microsoft.com/azure/architecture/patterns/gateway-routing" class="text_4">Gateway routing pattern</a><span class="text_5">.</span></p>
	<p class="block_14"><b class="calibre5">Requests aggregation.</b> As part of the gateway pattern you can aggregate multiple client requests (usually HTTP requests) targeting multiple internal microservices into a single client request. This pattern is especially convenient when a client page/screen needs information from several microservices. With this approach, the client app sends a single request to the API Gateway that dispatches several requests to the internal microservices and then aggregates the results and sends everything back to the client app. The main benefit and goal of this design pattern is to reduce chattiness between the client apps and the backend API, which is especially important for remote apps out of the datacenter where the microservices live, like mobile apps or requests coming from SPA apps that come from Javascript in client remote browsers. For regular web apps performing the requests in the server environment (like an ASP.NET Core MVC web app), this pattern is not so important as the latency is very much smaller than for remote client apps.</p>
	<p class="block_14">Depending on the API Gateway product you use, it might be able to perform this aggregation. However, in many cases it’s more flexible to create aggregation microservices under the scope of the API Gateway, so you define the aggregation in code (that is, C# code):</p>
	<p class="block_17"><span class="text_5">For more information, see </span><a href="https://docs.microsoft.com/azure/architecture/patterns/gateway-aggregation" class="text_4">Gateway aggregation pattern</a><span class="text_5">.</span></p>
	<p class="block_14"><b class="calibre5">Cross-cutting concerns or gateway offloading.</b> Depending on the features offered by each API Gateway product, you can offload functionality from individual microservices to the gateway, which simplifies the implementation of each microservice by consolidating cross-cutting concerns into one tier. This is especially convenient for specialized features that can be complex to implement properly in every internal microservice, such as the following functionality:</p>
	<ul class="list_">
	<li class="block_25">Authentication and authorization</li>
	<li class="block_25">Service discovery integration</li>
	<li class="block_25">Response caching</li>
	<li class="block_25">Retry policies, circuit breaker, and QoS</li>
	<li class="block_25">Rate limiting and throttling</li>
	<li class="block_25">Load balancing</li>
	<li class="block_25">Logging, tracing, correlation</li>
	<li class="block_25">Headers, query strings, and claims transformation</li>
	<li class="block_25">IP whitelisting</li>
</ul>
	<p class="block_17"><span class="text_5">For more information, see </span><a href="https://docs.microsoft.com/azure/architecture/patterns/gateway-offloading" class="text_4">Gateway offloading pattern</a><span class="text_5">.</span></p>
	<h2 id="id_Toc534713560" class="block_18">Using products with API Gateway features</h2>
	<p class="block_14">There can be many more cross-cutting concerns offered by the API Gateways products depending on each implementation. We’ll explore here:</p>
	<ul class="list_">
	<li class="block_20"><a href="https://azure.microsoft.com/services/api-management/" class="text_1">Azure API Management</a></li>
	<li class="block_20"><a href="https://github.com/ThreeMammals/Ocelot" class="text_1">Ocelot</a></li>
</ul>
	<h3 id="id_Toc534713561" class="block_19">Azure API Management</h3>
	<p class="block_17"><a href="https://azure.microsoft.com/services/api-management/" class="text_4">Azure API Management</a><span class="text_5"> (as shown in Figure 4-14) not only solves your API Gateway needs but provides features like gathering insights from your APIs. If you’re using an API management solution, an API Gateway is only a component within that full API management solution.</span></p>
	<p class="block_14"><img src="images/image-19.png" alt="C:\Users\Miguel\source\repos\dotnet\docs\docs\standard\microservices-architecture\architect-microservice-container-applications\media\image14.png" class="calibre30"/></p>
	<p class="block_23"><span class="text_6">Figure 4-14</span><i class="calibre8">. Using Azure API Management for your API Gateway</i></p>
	<p class="block_14">In this case, when using a product like Azure API Management, the fact that you might have a single API Gateway is not so risky because these kinds of API Gateways are “thinner”, meaning that you don’t implement custom C# code that could evolve towards a monolithic component. </p>
	<p class="block_14">The API Gateway products usually act like a reverse proxy for ingress communication, where you can also filter the APIs from the internal microservices plus apply authorization to the published APIs in this single tier.</p>
	<p class="block_14">The insights available from an API Management system help you get an understanding of how your APIs are being used and how they are performing. They do this by letting you view near real-time analytics reports and identifying trends that might impact your business. Plus, you can have logs about request and response activity for further online and offline analysis.</p>
	<p class="block_14">With Azure API Management, you can secure your APIs using a key, a token, and IP filtering. These features let you enforce flexible and fine-grained quotas and rate limits, modify the shape and behavior of your APIs using policies, and improve performance with response caching.</p>
	<p class="block_14">In this guide and the reference sample application (eShopOnContainers), the architecture is limited to a simpler and custom-made containerized architecture in order to focus on plain containers without using PaaS products like Azure API Management. But for large microservice-based applications that are deployed into Microsoft Azure, we encourage you to evaluate Azure API Management as the base for your API Gateways in production.</p>
	<h3 id="id_Toc534713562" class="block_19">Ocelot</h3>
	<p class="block_17"><a href="https://github.com/ThreeMammals/Ocelot" class="text_4">Ocelot</a><span class="text_5"> is a lightweight API Gateway, recommended for simpler approaches. Ocelot is an Open Source .NET Core based API Gateway especially made for microservices architecture that need unified points of entry into their system. It’s lightweight, fast, scalable and provides routing and authentication among many other features.</span></p>
	<p class="block_17"><span class="text_5">The main reason to choose Ocelot for the </span><a href="https://github.com/dotnet-architecture/eShopOnContainers" class="text_4">eShopOnContainers reference application</a><span class="text_5"> is because Ocelot is a .NET Core lightweight API Gateway that you can deploy into the same application deployment environment where you’re deploying your microservices/containers, such as a Docker Host, Kubernetes, Service Fabric, etc. And since it’s based on .NET Core, it’s cross-platform allowing you to deploy on Linux or Windows.</span></p>
	<p class="block_14">The previous diagrams showing custom API Gateways running in containers are precisely how you can also run Ocelot in a container and microservice-based application.</p>
	<p class="block_14">In addition, there are many other products in the market offering API Gateways features, such as Apigee, Kong, MuleSoft, WSO2, and other products like Linkerd and Istio for service mesh ingress controller features.</p>
	<p class="block_17"><span class="text_5">After the initial architecture and patterns explanation sections, the next sections explain how to implement API Gateways with </span><a href="https://github.com/ThreeMammals/Ocelot" class="text_4">Ocelot</a><span class="text_5">.</span></p>
	<h2 id="id_Toc534713563" class="block_18">Drawbacks of the API Gateway pattern</h2>
	<ul class="list_">
	<li class="block_20"><span class="text_">The most important drawback is that when you implement an API Gateway, you’re coupling that tier with the internal microservices. Coupling like this might introduce serious difficulties for your application. Clemens Vaster, architect at the Azure Service Bus team, refers to this potential difficulty as “the new ESB” in the “</span><a href="https://www.youtube.com/watch?v=rXi5CLjIQ9k" class="text_1">Messaging and Microservices</a><span class="text_">” session at GOTO 2016.</span></li>
	<li class="block_25">Using a microservices API Gateway creates an additional possible single point of failure.</li>
	<li class="block_25">An API Gateway can introduce increased response time due to the additional network call. However, this extra call usually has less impact than having a client interface that’s too chatty directly calling the internal microservices.</li>
	<li class="block_25">If not scaled out properly, the API Gateway can become a bottleneck.</li>
	<li class="block_25">An API Gateway requires additional development cost and future maintenance if it includes custom logic and data aggregation. Developers must update the API Gateway in order to expose each microservice’s endpoints. Moreover, implementation changes in the internal microservices might cause code changes at the API Gateway level. However, if the API Gateway is just applying security, logging, and versioning (as when using Azure API Management), this additional development cost might not apply.</li>
	<li class="block_25">If the API Gateway is developed by a single team, there can be a development bottleneck. This is another reason why a better approach is to have several fined-grained API Gateways that respond to different client needs. You could also segregate the API Gateway internally into multiple areas or layers that are owned by the different teams working on the internal microservices.</li>
</ul>
	<h2 id="id_Toc534713564" class="block_18">Additional resources</h2>
	<ul class="list_">
	<li class="block_20"><span class="text_2">Charles Richardson. Pattern: API Gateway / Backend for Front-End</span><span class="text_"><br class="calibre6"/></span><a href="https://microservices.io/patterns/apigateway.html" class="text_1">https://microservices.io/patterns/apigateway.html</a></li>
	<li class="block_20"><span class="text_2">API Gateway pattern</span><span class="text_"><br class="calibre6"/></span><a href="https://docs.microsoft.com/azure/architecture/microservices/gateway" class="text_1">https://docs.microsoft.com/azure/architecture/microservices/gateway</a></li>
	<li class="block_20"><span class="text_2">Aggregation and composition pattern</span><span class="text_"><br class="calibre6"/></span><a href="https://microservices.io/patterns/data/api-composition.html" class="text_1">https://microservices.io/patterns/data/api-composition.html</a></li>
	<li class="block_20"><span class="text_2">Azure API Management</span><span class="text_"><br class="calibre6"/></span><a href="https://azure.microsoft.com/services/api-management/" class="text_1">https://azure.microsoft.com/services/api-management/</a></li>
	<li class="block_20"><span class="text_2">Udi Dahan. Service Oriented Composition</span><span class="text_"><br class="calibre6"/></span><a href="http://udidahan.com/2014/07/30/service-oriented-composition-with-video/" class="text_1">http://udidahan.com/2014/07/30/service-oriented-composition-with-video/</a></li>
	<li class="block_20"><span class="text_2">Clemens Vasters. Messaging and Microservices at GOTO 2016 (video)</span><span class="text_"><br class="calibre6"/></span><a href="https://www.youtube.com/watch?v=rXi5CLjIQ9k" class="text_1">https://www.youtube.com/watch?v=rXi5CLjIQ9k</a></li>
	<li class="block_20"><span class="text_2">API Gateway in a Nutshell</span><span class="text_"> (ASP.net Core API Gateway Tutorial Series)<br class="calibre6"/></span><a href="https://www.pogsdotnet.com/2018/08/api-gateway-in-nutshell.html" class="text_1">https://www.pogsdotnet.com/2018/08/api-gateway-in-nutshell.html</a></li>
</ul>
	<h1 id="id_Toc534713565" class="block_24">Communication in a microservice architecture</h1>
	<p class="block_15"><span class="text_12">In a monolithic application running on a single process, components invoke one another using language-level method or function calls. These can be strongly coupled if you’re creating objects with code (for example, </span><span class="text_13">new ClassName()</span><span class="text_12">), or can be invoked in a decoupled way if you’re using Dependency Injection by referencing abstractions rather than concrete object instances. Either way, the objects are running within the same process. The biggest challenge when changing from a monolithic application to a microservices-based application lies in changing the communication mechanism. A direct conversion from in-process method calls into RPC calls to services will cause a chatty and not efficient communication that won’t perform well in distributed environments. The challenges of designing distributed system properly are well enough known that there’s even a canon known as the </span><a href="https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing" class="text_14">Fallacies of distributed computing</a><span class="text_12"> that lists assumptions that developers often make when moving from monolithic to distributed designs.</span></p>
	<p class="block_14">There isn’t one solution, but several. One solution involves isolating the business microservices as much as possible. You then use asynchronous communication between the internal microservices and replace fine-grained communication that’s typical in intra-process communication between objects with coarser-grained communication. You can do this by grouping calls, and by returning data that aggregates the results of multiple internal calls, to the client.</p>
	<p class="block_14">A microservices-based application is a distributed system running on multiple processes or services, usually even across multiple servers or hosts. Each service instance is typically a process. Therefore, services must interact using an inter-process communication protocol such as HTTP, AMQP, or a binary protocol like TCP, depending on the nature of each service.</p>
	<p class="block_17"><span class="text_5">The microservice community promotes the philosophy of “</span><a href="https://simplicable.com/new/smart-endpoints-and-dumb-pipes" class="text_4">smart endpoints and dumb pipes</a><span class="text_5">” This slogan encourages a design that’s as decoupled as possible between microservices, and as cohesive as possible within a single microservice. As explained earlier, each microservice owns its own data and its own domain logic. But the microservices composing an end-to-end application are usually simply choreographed by using REST communications rather than complex protocols such as WS-* and flexible event-driven communications instead of centralized business-process-orchestrators.</span></p>
	<p class="block_14">The two commonly used protocols are HTTP request/response with resource APIs (when querying most of all), and lightweight asynchronous messaging when communicating updates across multiple microservices. These are explained in more detail in the following sections.</p>
	<h2 id="id_Toc534713566" class="block_18">Communication types</h2>
	<p class="block_14">Client and services can communicate through many different types of communication, each one targeting a different scenario and goals. Initially, those types of communications can be classified in two axes.</p>
	<p class="block_14">The first axis defines if the protocol is synchronous or asynchronous:</p>
	<ul class="list_">
	<li class="block_25">Synchronous protocol. HTTP is a synchronous protocol. The client sends a request and waits for a response from the service. That’s independent of the client code execution that could be synchronous (thread is blocked) or asynchronous (thread isn’t blocked, and the response will reach a callback eventually). The important point here is that the protocol (HTTP/HTTPS) is synchronous and the client code can only continue its task when it receives the HTTP server response.</li>
	<li class="block_25">Asynchronous protocol. Other protocols like AMQP (a protocol supported by many operating systems and cloud environments) use asynchronous messages. The client code or message sender usually doesn’t wait for a response. It just sends the message as when sending a message to a RabbitMQ queue or any other message broker.</li>
</ul>
	<p class="block_14">The second axis defines if the communication has a single receiver or multiple receivers:</p>
	<ul class="list_">
	<li class="block_20"><span class="text_">Single receiver. Each request must be processed by exactly one receiver or service. An example of this communication is the </span><a href="https://en.wikipedia.org/wiki/Command_pattern" class="text_1">Command pattern</a><span class="text_">.</span></li>
	<li class="block_20"><span class="text_">Multiple receivers. Each request can be processed by zero to multiple receivers. This type of communication must be asynchronous. An example is the </span><a href="https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern" class="text_1">publish/subscribe</a><span class="text_"> mechanism used in patterns like </span><a href="https://microservices.io/patterns/data/event-driven-architecture.html" class="text_1">Event-driven architecture</a><span class="text_">. This is based on an event-bus interface or message broker when propagating data updates between multiple microservices through events; it’s usually implemented through a service bus or similar artifact like </span><a href="https://azure.microsoft.com/services/service-bus/" class="text_1">Azure Service Bus</a><span class="text_"> by using </span><a href="https://docs.microsoft.com/azure/service-bus-messaging/service-bus-dotnet-how-to-use-topics-subscriptions" class="text_1">topics and subscriptions</a><span class="text_">.</span></li>
</ul>
	<p class="block_14">A microservice-based application will often use a combination of these communication styles. The most common type is single-receiver communication with a synchronous protocol like HTTP/HTTPS when invoking a regular Web API HTTP service. Microservices also typically use messaging protocols for asynchronous communication between microservices.</p>
	<p class="block_14">These axes are good to know so you have clarity on the possible communication mechanisms, but they’re not the important concerns when building microservices. Neither the asynchronous nature of client thread execution nor the asynchronous nature of the selected protocol are the important points when integrating microservices. What <i class="calibre15">is</i> important is being able to integrate your microservices asynchronously while maintaining the independence of microservices, as explained in the following section.</p>
	<h2 id="id_Toc534713567" class="block_18">Asynchronous microservice integration enforces microservice’s autonomy</h2>
	<p class="block_14">As mentioned, the important point when building a microservices-based application is the way you integrate your microservices. Ideally, you should try to minimize the communication between the internal microservices. The fewer communications between microservices, the better. But in many cases, you’ll have to somehow integrate the microservices. When you need to do that, the critical rule here is that the communication between the microservices should be asynchronous. That doesn’t mean that you have to use a specific protocol (for example, asynchronous messaging versus synchronous HTTP). It just means that the communication between microservices should be done only by propagating data asynchronously, but try not to depend on other internal microservices as part of the initial service’s HTTP request/response operation.</p>
	<p class="block_14">If possible, never depend on synchronous communication (request/response) between multiple microservices, not even for queries. The goal of each microservice is to be autonomous and available to the client consumer, even if the other services that are part of the end-to-end application are down or unhealthy. If you think you need to make a call from one microservice to other microservices (like performing an HTTP request for a data query) to be able to provide a response to a client application, you have an architecture that won’t be resilient when some microservices fail.</p>
	<p class="block_14">Moreover, having HTTP dependencies between microservices, like when creating long request/response cycles with HTTP request chains, as shown in the first part of the Figure 4-15, not only makes your microservices not autonomous but also their performance is impacted as soon as one of the services in that chain isn’t performing well.</p>
	<p class="block_14">The more you add synchronous dependencies between microservices, such as query requests, the worse the overall response time gets for the client apps.</p>
	<p class="block_14"><img src="images/image-20.png" alt="C:\Users\Miguel\source\repos\dotnet\docs\docs\standard\microservices-architecture\architect-microservice-container-applications\media\image15.png" class="calibre26"/></p>
	<p class="block_23"><span class="text_6">Figure 4-15</span><i class="calibre8">. Anti-patterns and patterns in communication between microservices</i></p>
	<p class="block_14">If your microservice needs to raise an additional action in another microservice, if possible, do not perform that action synchronously and as part of the original microservice request and reply operation. Instead, do it asynchronously (using asynchronous messaging or integration events, queues, etc.). But, as much as possible, do not invoke the action synchronously as part of the original synchronous request and reply operation.</p>
	<p class="block_14">And finally (and this is where most of the issues arise when building microservices), if your initial microservice needs data that’s originally owned by other microservices, do not rely on making synchronous requests for that data. Instead, replicate or propagate that data (only the attributes you need) into the initial service’s database by using eventual consistency (typically by using integration events, as explained in upcoming sections).</p>
	<p class="block_17"><span class="text_5">As noted earlier in the section </span><a href="#id_Toc534713554" class="text_4">Identifying domain-model boundaries for each microservice</a><span class="text_5">, duplicating some data across several microservices isn’t an incorrect design—on the contrary, when doing that you can translate the data into the specific language or terms of that additional domain or Bounded Context. For instance, in the </span><a href="https://github.com/dotnet-architecture/eShopOnContainers" class="text_4">eShopOnContainers application</a><span class="text_5"> you have a microservice named identity.api that’s in charge of most of the user’s data with an entity named User. However, when you need to store data about the user within the Ordering microservice, you store it as a different entity named Buyer. The Buyer entity shares the same identity with the original User entity, but it might have only the few attributes needed by the Ordering domain, and not the whole user profile.</span></p>
	<p class="block_14">You might use any protocol to communicate and propagate data asynchronously across microservices in order to have eventual consistency. As mentioned, you could use integration events using an event bus or message broker or you could even use HTTP by polling the other services instead. It doesn’t matter. The important rule is to not create synchronous dependencies between your microservices.</p>
	<p class="block_14">The following sections explain the multiple communication styles you can consider using in a microservice-based application.</p>
	<h2 id="id_Toc534713568" class="block_18">Communication styles</h2>
	<p class="block_14">There are many protocols and choices you can use for communication, depending on the communication type you want to use. If you’re using a synchronous request/response-based communication mechanism, protocols such as HTTP and REST approaches are the most common, especially if you’re publishing your services outside the Docker host or microservice cluster. If you’re communicating between services internally (within your Docker host or microservices cluster), you might also want to use binary format communication mechanisms (like Service Fabric remoting or WCF using TCP and binary format). Alternatively, you can use asynchronous, message-based communication mechanisms such as AMQP.</p>
	<p class="block_14">There are also multiple message formats like JSON or XML, or even binary formats, which can be more efficient. If your chosen binary format isn’t a standard, it’s probably not a good idea to publicly publish your services using that format. You could use a non-standard format for internal communication between your microservices. You might do this when communicating between microservices within your Docker host or microservice cluster (Docker orchestrators or Azure Service Fabric), or for proprietary client applications that talk to the microservices.</p>
	<h3 id="id_Toc534713569" class="block_19">Request/response communication with HTTP and REST</h3>
	<p class="block_14">When a client uses request/response communication, it sends a request to a service, then the service processes the request and sends back a response. Request/response communication is especially well suited for querying data for a real-time UI (a live user interface) from client apps. Therefore, in a microservice architecture you’ll probably use this communication mechanism for most queries, as shown in Figure 4-16.</p>
	<p class="block_14"><img src="images/image-21.png" alt="C:\Users\Miguel\source\repos\dotnet\docs\docs\standard\microservices-architecture\architect-microservice-container-applications\media\image16.png" class="calibre31"/></p>
	<p class="block_23"><span class="text_6">Figure 4-16</span><i class="calibre8">. Using HTTP request/response communication (synchronous or asynchronous)</i></p>
	<p class="block_17"><span class="text_5">When a client uses request/response communication, it assumes that the response will arrive in a short time, typically less than a second, or a few seconds at most. For delayed responses, you need to implement asynchronous communication based on </span><a href="https://docs.microsoft.com/azure/architecture/patterns/category/messaging" class="text_4">messaging patterns</a><span class="text_5"> and </span><a href="https://en.wikipedia.org/wiki/Message-oriented_middleware" class="text_4">messaging technologies</a><span class="text_5">, which is a different approach that we explain in the next section.</span></p>
	<p class="block_17"><span class="text_5">A popular architectural style for request/response communication is </span><a href="https://en.wikipedia.org/wiki/Representational_state_transfer" class="text_4">REST</a><span class="text_5">. This approach is based on, and tightly coupled to, the </span><a href="https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol" class="text_4">HTTP</a><span class="text_5"> protocol, embracing HTTP verbs like GET, POST, and PUT. REST is the most commonly used architectural communication approach when creating services. You can implement REST services when you develop ASP.NET Core Web API services.</span></p>
	<p class="block_17"><span class="text_5">There’s additional value when using HTTP REST services as your interface definition language. For instance, if you use </span><a href="https://swagger.io/" class="text_4">Swagger metadata</a><span class="text_5"> to describe your service API, you can use tools that generate client stubs that can directly discover and consume your services.</span></p>
	<h3 id="id_Toc534713570" class="block_19">Additional resources</h3>
	<ul class="list_">
	<li class="block_20"><span class="text_2">Martin Fowler. Richardson Maturity Model</span><span class="text_"> A description of the REST model.<br class="calibre6"/></span><a href="https://martinfowler.com/articles/richardsonMaturityModel.html" class="text_1">https://martinfowler.com/articles/richardsonMaturityModel.html</a></li>
	<li class="block_20"><span class="text_2">Swagger</span><span class="text_"> The official site.<br class="calibre6"/></span><a href="https://swagger.io/" class="text_1">https://swagger.io/</a></li>
</ul>
	<h3 id="id_Toc534713571" class="block_19">Push and real-time communication based on HTTP</h3>
	<p class="block_17"><span class="text_5">Another possibility (usually for different purposes than REST) is a real-time and one-to-many communication with higher-level frameworks such as </span><a href="https://www.asp.net/signalr" class="text_4">ASP.NET SignalR</a><span class="text_5"> and protocols such as </span><a href="https://en.wikipedia.org/wiki/WebSocket" class="text_4">WebSockets</a><span class="text_5">.</span></p>
	<p class="block_14">As Figure 4-17 shows, real-time HTTP communication means that you can have server code pushing content to connected clients as the data becomes available, rather than having the server wait for a client to request new data.</p>
	<p class="block_14"><img src="images/image-22.png" alt="C:\Users\Miguel\source\repos\dotnet\docs\docs\standard\microservices-architecture\architect-microservice-container-applications\media\image17.png" class="calibre32"/></p>
	<p class="block_23"><span class="text_6">Figure 4-17</span><i class="calibre8">. One-to-one real-time asynchronous message communication</i></p>
	<p class="block_14">Since communication is in real time, client apps show the changes almost instantly. This is usually handled by a protocol such as WebSockets, using many WebSockets connections (one per client). A typical example is when a service communicates a change in the score of a sports game to many client web apps simultaneously.</p>
	<h1 id="id_Toc534713572" class="block_24">Asynchronous message-based communication</h1>
	<p class="block_14">Asynchronous messaging and event-driven communication are critical when propagating changes across multiple microservices and their related domain models. As mentioned earlier in the discussion microservices and Bounded Contexts (BCs), models (User, Customer, Product, Account, etc.) can mean different things to different microservices or BCs. That means that when changes occur, you need some way to reconcile changes across the different models. A solution is eventual consistency and event-driven communication based on asynchronous messaging.</p>
	<p class="block_14">When using messaging, processes communicate by exchanging messages asynchronously. A client makes a command or a request to a service by sending it a message. If the service needs to reply, it sends a different message back to the client. Since it’s a message-based communication, the client assumes that the reply won’t be received immediately, and that there might be no response at all.</p>
	<p class="block_14">A message is composed by a header (metadata such as identification or security information) and a body. Messages are usually sent through asynchronous protocols like AMQP.</p>
	<p class="block_14">The preferred infrastructure for this type of communication in the microservices community is a lightweight message broker, which is different than the large brokers and orchestrators used in SOA. In a lightweight message broker, the infrastructure is typically “dumb,” acting only as a message broker, with simple implementations such as RabbitMQ or a scalable service bus in the cloud like Azure Service Bus. In this scenario, most of the “smart” thinking still lives in the endpoints that are producing and consuming messages-that is, in the microservices.</p>
	<p class="block_14">Another rule you should try to follow, as much as possible, is to use only asynchronous messaging between the internal services, and to use synchronous communication (such as HTTP) only from the client apps to the front-end services (API Gateways plus the first level of microservices).</p>
	<p class="block_14">There are two kinds of asynchronous messaging communication: single receiver message-based communication, and multiple receivers message-based communication. The following sections provide details about them.</p>
	<h2 id="id_Toc534713573" class="block_18">Single-receiver message-based communication</h2>
	<p class="block_14">Message-based asynchronous communication with a single receiver means there’s point-to-point communication that delivers a message to exactly one of the consumers that’s reading from the channel, and that the message is processed just once. However, there are special situations. For instance, in a cloud system that tries to automatically recover from failures, the same message could be sent multiple times. Due to network or other failures, the client has to be able to retry sending messages, and the server has to implement an operation to be idempotent in order to process a particular message just once.</p>
	<p class="block_14">Single-receiver message-based communication is especially well suited for sending asynchronous commands from one microservice to another as shown in Figure 4-18 that illustrates this approach.</p>
	<p class="block_14">Once you start sending message-based communication (either with commands or events), you should avoid mixing message-based communication with synchronous HTTP communication.</p>
	<p class="block_14"><img src="images/image-23.png" alt="C:\Users\Miguel\source\repos\dotnet\docs\docs\standard\microservices-architecture\architect-microservice-container-applications\media\image18.png" class="calibre33"/></p>
	<p class="block_23"><span class="text_6">Figure 4-18</span><i class="calibre8">. A single microservice receiving an asynchronous message</i></p>
	<p class="block_14">Note that when the commands come from client applications, they can be implemented as HTTP synchronous commands. You should use message-based commands when you need higher scalability or when you’re already in a message-based business process.</p>
	<h2 id="id_Toc534713574" class="block_18">Multiple-receivers message-based communication</h2>
	<p class="block_17"><span class="text_5">As a more flexible approach, you might also want to use a publish/subscribe mechanism so that your communication from the sender will be available to additional subscriber microservices or to external applications. Thus, it helps you to follow the </span><a href="https://en.wikipedia.org/wiki/Open/closed_principle" class="text_4">open/closed principle</a><span class="text_5"> in the sending service. That way, additional subscribers can be added in the future without the need to modify the sender service.</span></p>
	<p class="block_14">When you use a publish/subscribe communication, you might be using an event bus interface to publish events to any subscriber.</p>
	<h2 id="id_Toc534713575" class="block_18">Asynchronous event-driven communication</h2>
	<p class="block_14">When using asynchronous event-driven communication, a microservice publishes an integration event when something happens within its domain and another microservice needs to be aware of it, like a price change in a product catalog microservice. Additional microservices subscribe to the events so they can receive them asynchronously. When that happens, the receivers might update their own domain entities, which can cause more integration events to be published. This publish/subscribe system is usually performed by using an implementation of an event bus. The event bus can be designed as an abstraction or interface, with the API that’s needed to subscribe or unsubscribe to events and to publish events. The event bus can also have one or more implementations based on any inter-process and messaging broker, like a messaging queue or service bus that supports asynchronous communication and a publish/subscribe model.</p>
	<p class="block_14">If a system uses eventual consistency driven by integration events, it’s recommended that this approach is made completely clear to the end user. The system shouldn’t use an approach that mimics integration events, like SignalR or polling systems from the client. The end user and the business owner have to explicitly embrace eventual consistency in the system and realize that in many cases the business doesn’t have any problem with this approach, as long as it’s explicit. This is important because users might expect to see some results immediately and this might not happen with eventual consistency.</p>
	<p class="block_17"><span class="text_5">As noted earlier in the </span><a href="#id_Toc534713548" class="text_4">Challenges and solutions for distributed data management</a><span class="text_5"> section, you can use integration events to implement business tasks that span multiple microservices. Thus, you’ll have eventual consistency between those services. An eventually consistent transaction is made up of a collection of distributed actions. At each action, the related microservice updates a domain entity and publishes another integration event that raises the next action within the same end-to-end business task.</span></p>
	<p class="block_17"><span class="text_5">An important point is that you might want to communicate to multiple microservices that are subscribed to the same event. To do so, you can use publish/subscribe messaging based on event-driven communication, as shown in Figure 4-19. This publish/subscribe mechanism isn’t exclusive to the microservice architecture. It’s similar to the way </span><a href="https://martinfowler.com/bliki/BoundedContext.html" class="text_4">Bounded Contexts</a><span class="text_5"> in DDD should communicate, or to the way you propagate updates from the write database to the read database in the </span><a href="https://martinfowler.com/bliki/CQRS.html" class="text_4">Command and Query Responsibility Segregation (CQRS)</a><span class="text_5"> architecture pattern. The goal is to have eventual consistency between multiple data sources across your distributed system.</span></p>
	<p class="block_14"><img src="images/image-24.png" alt="C:\Users\Miguel\source\repos\dotnet\docs\docs\standard\microservices-architecture\architect-microservice-container-applications\media\image19.png" class="calibre34"/></p>
	<p class="block_23"><span class="text_6">Figure 4-19</span><i class="calibre8">. Asynchronous event-driven message communication</i></p>
	<p class="block_17"><span class="text_5">Your implementation will determine what protocol to use for event-driven, message-based communications. </span><a href="https://en.wikipedia.org/wiki/Advanced_Message_Queuing_Protocol" class="text_4">AMQP</a><span class="text_5"> can help achieve reliable queued communication.</span></p>
	<p class="block_17"><span class="text_5">When you use an event bus, you might want to use an abstraction level (like an event bus interface) based on a related implementation in classes with code using the API from a message broker like </span><a href="https://www.rabbitmq.com/" class="text_4">RabbitMQ</a><span class="text_5"> or a service bus like </span><a href="https://docs.microsoft.com/azure/service-bus-messaging/service-bus-dotnet-how-to-use-topics-subscriptions" class="text_4">Azure Service Bus with Topics</a><span class="text_5">. Alternatively, you might want to use a higher-level service bus like NServiceBus, MassTransit, or Brighter to articulate your event bus and publish/subscribe system.</span></p>
	<h2 id="id_Toc534713576" class="block_18">A note about messaging technologies for production systems</h2>
	<p class="block_14">The messaging technologies available for implementing your abstract event bus are at different levels. For instance, products like RabbitMQ (a messaging broker transport) and Azure Service Bus sit at a lower level than other products like, NServiceBus, MassTransit, or Brighter, which can work on top of RabbitMQ and Azure Service Bus. Your choice depends on how many rich features at the application level and out-of-the-box scalability you need for your application. For implementing just a proof-of-concept event bus for your development environment, as it was done in the eShopOnContainers sample, a simple implementation on top of RabbitMQ running on a Docker container might be enough.</p>
	<p class="block_14">However, for mission-critical and production systems that need hyper-scalability, you might want to evaluate Azure Service Bus. For high-level abstractions and features that make the development of distributed applications easier, we recommend that you evaluate other commercial and open-source service buses, such as NServiceBus, MassTransit, and Brighter. Of course, you can build your own service-bus features on top of lower-level technologies like RabbitMQ and Docker. But that plumbing work might cost too much for a custom enterprise application.</p>
	<h2 id="id_Toc534713577" class="block_18">Resiliently publishing to the event bus</h2>
	<p class="block_14">A challenge when implementing an event-driven architecture across multiple microservices is how to atomically update state in the original microservice while resiliently publishing its related integration event into the event bus, somehow based on transactions. The following are a few ways to accomplish this, although there could be additional approaches as well.</p>
	<ul class="list_">
	<li class="block_25">Using a transactional (DTC-based) queue like MSMQ. (However, this is a legacy approach.)</li>
	<li class="block_20"><span class="text_">Using </span><a href="https://www.scoop.it/t/sql-server-transaction-log-mining" class="text_1">transaction log mining</a><span class="text_">.</span></li>
	<li class="block_20"><span class="text_">Using full </span><a href="https://msdn.microsoft.com/library/dn589792.aspx" class="text_1">Event Sourcing</a><span class="text_"> pattern.</span></li>
	<li class="block_20"><span class="text_">Using the </span><a href="http://gistlabs.com/2014/05/the-outbox/" class="text_1">Outbox pattern</a><span class="text_">: a transactional database table as a message queue that will be the base for an event-creator component that would create the event and publish it.</span></li>
</ul>
	<p class="block_17"><span class="text_5">Additional topics to consider when using asynchronous communication are message idempotence and message deduplication. These topics are covered in the section </span><a href="index_split_009.html#id_Toc534713675" class="calibre4"><span class="text_4">Implementing event-based communication between microservices (integration events)</span></a><span class="text_5"> later in this guide.</span></p>
	<h2 id="id_Toc534713578" class="block_18">Additional resources</h2>
	<ul class="list_">
	<li class="block_20"><span class="text_2">Event Driven Messaging</span><span class="text_"><br class="calibre6"/></span><a href="http://soapatterns.org/design_patterns/event_driven_messaging" class="text_1">http://soapatterns.org/design_patterns/event_driven_messaging</a></li>
	<li class="block_20"><span class="text_2">Publish/Subscribe Channel</span><span class="text_"><br class="calibre6"/></span><a href="https://www.enterpriseintegrationpatterns.com/patterns/messaging/PublishSubscribeChannel.html" class="text_1">https://www.enterpriseintegrationpatterns.com/patterns/messaging/PublishSubscribeChannel.html</a></li>
	<li class="block_20"><span class="text_2">Udi Dahan. Clarified CQRS</span><span class="text_"><br class="calibre6"/></span><a href="http://udidahan.com/2009/12/09/clarified-cqrs/" class="text_1">http://udidahan.com/2009/12/09/clarified-cqrs/</a></li>
	<li class="block_20"><span class="text_2">Command and Query Responsibility Segregation (CQRS)</span><span class="text_"><br class="calibre6"/></span><a href="https://docs.microsoft.com/azure/architecture/patterns/cqrs" class="text_1">https://docs.microsoft.com/azure/architecture/patterns/cqrs</a></li>
	<li class="block_20"><span class="text_2">Communicating Between Bounded Contexts</span><span class="text_"><br class="calibre6"/></span><a href="https://docs.microsoft.com/previous-versions/msp-n-p/jj591572(v=pandp.10)" class="text_1">https://docs.microsoft.com/previous-versions/msp-n-p/jj591572(v=pandp.10)</a></li>
	<li class="block_20"><span class="text_2">Eventual consistency</span><span class="text_"><br class="calibre6"/></span><a href="https://en.wikipedia.org/wiki/Eventual_consistency" class="text_1">https://en.wikipedia.org/wiki/Eventual_consistency</a></li>
	<li class="block_20"><span class="text_2">Jimmy Bogard. Refactoring Towards Resilience: Evaluating Coupling</span><span class="text_"><br class="calibre6"/></span><a href="https://jimmybogard.com/refactoring-towards-resilience-evaluating-coupling/" class="text_1">https://jimmybogard.com/refactoring-towards-resilience-evaluating-coupling/</a></li>
</ul>
	<h1 id="id_Toc534713579" class="block_24">Creating, evolving, and versioning microservice APIs and contracts</h1>
	<p class="block_14">A microservice API is a contract between the service and its clients. You’ll be able to evolve a microservice independently only if you do not break its API contract, which is why the contract is so important. If you change the contract, it will impact your client applications or your API Gateway.</p>
	<p class="block_17"><span class="text_5">The nature of the API definition depends on which protocol you’re using. For instance, if you’re using messaging (like </span><a href="https://www.amqp.org/" class="text_4">AMQP</a><span class="text_5">), the API consists of the message types. If you’re using HTTP and RESTful services, the API consists of the URLs and the request and response JSON formats.</span></p>
	<p class="block_14">However, even if you’re thoughtful about your initial contract, a service API will need to change over time. When that happens—and especially if your API is a public API consumed by multiple client applications — you typically can’t force all clients to upgrade to your new API contract. You usually need to incrementally deploy new versions of a service in a way that both old and new versions of a service contract are running simultaneously. Therefore, it’s important to have a strategy for your service versioning.</p>
	<p class="block_14">When the API changes are small, like if you add attributes or parameters to your API, clients that use an older API should switch and work with the new version of the service. You might be able to provide default values for any missing attributes that are required, and the clients might be able to ignore any extra response attributes.</p>
	<p class="block_17"><span class="text_5">However, sometimes you need to make major and incompatible changes to a service API. Because you might not be able to force client applications or services to upgrade immediately to the new version, a service must support older versions of the API for some period. If you’re using an HTTP-based mechanism such as REST, one approach is to embed the API version number in the URL or into an HTTP header. Then you can decide between implementing both versions of the service simultaneously within the same service instance, or deploying different instances that each handle a version of the API. A good approach for this is the </span><a href="https://en.wikipedia.org/wiki/Mediator_pattern" class="text_4">Mediator pattern</a><span class="text_5"> (for example, </span><a href="https://github.com/jbogard/MediatR" class="text_4">MediatR library</a><span class="text_5">) to decouple the different implementation versions into independent handlers.</span></p>
	<p class="block_17"><span class="text_5">Finally, if you’re using a REST architecture, </span><a href="https://www.infoq.com/articles/mark-baker-hypermedia" class="text_4">Hypermedia</a><span class="text_5"> is the best solution for versioning your services and allowing evolvable APIs.</span></p>
	<h2 id="id_Toc534713580" class="block_18">Additional resources</h2>
	<ul class="list_">
	<li class="block_20"><span class="text_2">Scott Hanselman. ASP.NET Core RESTful Web API versioning made easy</span><span class="text_"><br class="calibre6"/></span><a href="https://www.hanselman.com/blog/ASPNETCoreRESTfulWebAPIVersioningMadeEasy.aspx" class="text_1">https://www.hanselman.com/blog/ASPNETCoreRESTfulWebAPIVersioningMadeEasy.aspx</a></li>
	<li class="block_20"><span class="text_2">Versioning a RESTful web API</span><span class="text_"><br class="calibre6"/></span><a href="https://docs.microsoft.com/azure/architecture/best-practices/api-design" class="text_1">https://docs.microsoft.com/azure/architecture/best-practices/api-design#versioning-a-restful-web-api</a></li>
	<li class="block_20"><span class="text_2">Roy Fielding. Versioning, Hypermedia, and REST</span><span class="text_"><br class="calibre6"/></span><a href="https://www.infoq.com/articles/roy-fielding-on-versioning" class="text_1">https://www.infoq.com/articles/roy-fielding-on-versioning</a></li>
</ul>
	<h1 id="id_Toc534713581" class="block_24">Microservices addressability and the service registry</h1>
	<p class="block_17"><span class="text_5">Each microservice has a unique name (URL) that’s used to resolve its location. Your microservice needs to be addressable wherever it’s running. If you have to think about which computer is running a particular microservice, things can go bad quickly. In the same way that DNS resolves a URL to a particular computer, your microservice needs to have a unique name so that its current location is discoverable. Microservices need addressable names that make them independent from the infrastructure that they’re running on. This implies that there’s an interaction between how your service is deployed and how it’s discovered, because there needs to be a </span><a href="https://microservices.io/patterns/service-registry.html" class="text_4">service registry</a><span class="text_5">. In the same vein, when a computer fails, the registry service must be able to indicate where the service is now running.</span></p>
	<p class="block_17"><span class="text_5">The </span><a href="https://microservices.io/patterns/service-registry.html" class="text_4">service registry pattern</a><span class="text_5"> is a key part of service discovery. The registry is a database containing the network locations of service instances. A service registry needs to be highly available and up-to-date. Clients could cache network locations obtained from the service registry. However, that information eventually goes out of date and clients can no longer discover service instances. Consequently, a service registry consists of a cluster of servers that use a replication protocol to maintain consistency.</span></p>
	<p class="block_14">In some microservice deployment environments (called clusters, to be covered in a later section), service discovery is built-in. For example, an Azure Container Service with Kubernetes (AKS) environment can handle service instance registration and deregistration. It also runs a proxy on each cluster host that plays the role of server-side discovery router. Another example is Azure Service Fabric, which also provides a service registry through its out-of-the-box Naming Service.</p>
	<p class="block_17"><span class="text_5">Note that there’s certain overlap between the service registry and the API gateway pattern, which helps solve this problem as well. For example, the </span><a href="https://docs.microsoft.com/azure/service-fabric/service-fabric-reverseproxy" class="text_4">Service Fabric Reverse Proxy</a><span class="text_5"> is a type of implementation of an API Gateway that’s based on the Service Fabric Naming Service and that helps resolve address resolution to the internal services.</span></p>
	<h2 id="id_Toc534713582" class="block_18">Additional resources</h2>
	<ul class="list_">
	<li class="block_20"><span class="text_2">Chris Richardson. Pattern: Service registry</span><span class="text_"><br class="calibre6"/></span><a href="https://microservices.io/patterns/service-registry.html" class="text_1">https://microservices.io/patterns/service-registry.html</a></li>
	<li class="block_20"><span class="text_2">Auth0. The Service Registry</span><span class="text_"><br class="calibre6"/></span><a href="https://auth0.com/blog/an-introduction-to-microservices-part-3-the-service-registry/" class="text_1">https://auth0.com/blog/an-introduction-to-microservices-part-3-the-service-registry/</a></li>
	<li class="block_20"><span class="text_2">Gabriel Schenker. Service discovery</span><span class="text_"><br class="calibre6"/></span><a href="https://lostechies.com/gabrielschenker/2016/01/27/service-discovery/" class="text_1">https://lostechies.com/gabrielschenker/2016/01/27/service-discovery/</a></li>
</ul>
	<h1 id="id_Toc534713583" class="block_24">Creating composite UI based on microservices</h1>
	<p class="block_14">Microservices architecture often starts with the server-side handling data and logic. However, a more advanced approach is to design your application UI based on microservices as well. That means having a composite UI produced by the microservices, instead of having microservices on the server and just a monolithic client app consuming the microservices. With this approach, the microservices you build can be complete with both logic and visual representation.</p>
	<p class="block_14">Figure 4-20 shows the simpler approach of just consuming microservices from a monolithic client application. Of course, you could have an ASP.NET MVC service in between producing the HTML and JavaScript. The figure is a simplification that highlights that you have a single (monolithic) client UI consuming the microservices, which just focus on logic and data and not on the UI shape (HTML and JavaScript).</p>
	<p class="block_14"><img src="images/image-25.png" alt="C:\Users\Miguel\source\repos\dotnet\docs\docs\standard\microservices-architecture\architect-microservice-container-applications\media\image20.png" class="calibre35"/></p>
	<p class="block_23"><span class="text_6">Figure 4-20</span><i class="calibre8">. A monolithic UI application consuming back-end microservices</i></p>
	<p class="block_14">In contrast, a composite UI is precisely generated and composed by the microservices themselves. Some of the microservices drive the visual shape of specific areas of the UI. The key difference is that you have client UI components (TypeScript classes, for example) based on templates, and the data-shaping-UI ViewModel for those templates comes from each microservice.</p>
	<p class="block_14">At client application start-up time, each of the client UI components (TypeScript classes, for example) registers itself with an infrastructure microservice capable of providing ViewModels for a given scenario. If the microservice changes the shape, the UI changes also.</p>
	<p class="block_14">Figure 4-21 shows a version of this composite UI approach. This is simplified because you might have other microservices that are aggregating granular parts that are based on different techniques. It depends on whether you’re building a traditional web approach (ASP.NET MVC) or an SPA (Single Page Application).</p>
	<p class="block_14"><img src="images/image-26.png" alt="C:\Users\Miguel\source\repos\dotnet\docs\docs\standard\microservices-architecture\architect-microservice-container-applications\media\image21.png" class="calibre36"/></p>
	<p class="block_23"><span class="text_6">Figure 4-21</span><i class="calibre8">. Example of a composite UI application shaped by back-end microservices</i></p>
	<p class="block_14">Each of those UI composition microservices would be similar to a small API Gateway. But in this case each one is responsible for a small UI area.</p>
	<p class="block_14">A composite UI approach that’s driven by microservices can be more challenging or less so, depending on what UI technologies you’re using. For instance, you won’t use the same techniques for building a traditional web application that you use for building an SPA or for native mobile app (as when developing Xamarin apps, which can be more challenging for this approach).</p>
	<p class="block_17"><span class="text_5">The </span><a href="https://aka.ms/MicroservicesArchitecture" class="text_4">eShopOnContainers</a><span class="text_5"> sample application uses the monolithic UI approach for multiple reasons. First, it’s an introduction to microservices and containers. A composite UI is more advanced but also requires further complexity when designing and developing the UI. Second, eShopOnContainers also provides a native mobile app based on Xamarin, which would make it more complex on the client C# side.</span></p>
	<p class="block_14">However, we encourage you to use the following references to learn more about composite UI based on microservices.</p>
	<h2 id="id_Toc534713584" class="block_18">Additional resources</h2>
	<ul class="list_">
	<li class="block_20"><span class="text_2">Composite UI using ASP.NET (Particular’s Workshop)</span><span class="text_"><br class="calibre6"/></span><a href="https://github.com/Particular/Workshop/tree/master/demos/asp-net-core" class="text_1">https://github.com/Particular/Workshop/tree/master/demos/asp-net-core</a></li>
	<li class="block_20"><span class="text_2">Ruben Oostinga. The Monolithic Frontend in the Microservices Architecture</span><span class="text_"><br class="calibre6"/></span><a href="https://blog.xebia.com/the-monolithic-frontend-in-the-microservices-architecture/" class="text_1">https://blog.xebia.com/the-monolithic-frontend-in-the-microservices-architecture/</a></li>
	<li class="block_20"><span class="text_2">Mauro Servienti. The secret of better UI composition</span><span class="text_"><br class="calibre6"/></span><a href="https://particular.net/blog/secret-of-better-ui-composition" class="text_1">https://particular.net/blog/secret-of-better-ui-composition</a></li>
	<li class="block_20"><span class="text_2">Viktor Farcic. Including Front-End Web Components Into Microservices</span><span class="text_"><br class="calibre6"/></span><a href="https://technologyconversations.com/2015/08/09/including-front-end-web-components-into-microservices/" class="text_1">https://technologyconversations.com/2015/08/09/including-front-end-web-components-into-microservices/</a></li>
	<li class="block_20"><span class="text_2">Managing Frontend in the Microservices Architecture</span><span class="text_"><br class="calibre6"/></span><a href="https://allegro.tech/2016/03/Managing-Frontend-in-the-microservices-architecture.html" class="text_1">https://allegro.tech/2016/03/Managing-Frontend-in-the-microservices-architecture.html</a></li>
</ul>
	<h1 id="id_Toc534713585" class="block_24">Resiliency and high availability in microservices</h1>
	<p class="block_14">Dealing with unexpected failures is one of the hardest problems to solve, especially in a distributed system. Much of the code that developers write involves handling exceptions, and this is also where the most time is spent in testing. The problem is more involved than writing code to handle failures. What happens when the machine where the microservice is running fails? Not only do you need to detect this microservice failure (a hard problem on its own), but you also need something to restart your microservice.</p>
	<p class="block_14">A microservice needs to be resilient to failures and to be able to restart often on another machine for availability. This resiliency also comes down to the state that was saved on behalf of the microservice, where the microservice can recover this state from, and whether the microservice can restart successfully. In other words, there needs to be resiliency in the compute capability (the process can restart at any time) as well as resilience in the state or data (no data loss, and the data remains consistent).</p>
	<p class="block_14">The problems of resiliency are compounded during other scenarios, such as when failures occur during an application upgrade. The microservice, working with the deployment system, needs to determine whether it can continue to move forward to the newer version or instead roll back to a previous version to maintain a consistent state. Questions such as whether enough machines are available to keep moving forward and how to recover previous versions of the microservice need to be considered. This requires the microservice to emit health information so that the overall application and orchestrator can make these decisions.</p>
	<p class="block_17"><span class="text_5">In addition, resiliency is related to how cloud-based systems must behave. As mentioned, a cloud-based system must embrace failures and must try to automatically recover from them. For instance, in case of network or container failures, client apps or client services must have a strategy to retry sending messages or to retry requests, since in many cases failures in the cloud are partial. The </span><a href="index_split_012.html#id_Toc534713834" class="text_4">Implementing Resilient Applications</a><span class="text_5"> section in this guide addresses how to handle partial failure. It describes techniques like retries with exponential backoff or the Circuit Breaker pattern in .NET Core by using libraries like </span><a href="https://github.com/App-vNext/Polly" class="text_4">Polly</a><span class="text_5">, which offers a large variety of policies to handle this subject.</span></p>
	<h2 id="id_Toc534713586" class="block_18">Health management and diagnostics in microservices</h2>
	<p class="block_14">It may seem obvious, and it’s often overlooked, but a microservice must report its health and diagnostics. Otherwise, there’s little insight from an operations perspective. Correlating diagnostic events across a set of independent services and dealing with machine clock skews to make sense of the event order is challenging. In the same way that you interact with a microservice over agreed-upon protocols and data formats, there’s a need for standardization in how to log health and diagnostic events that ultimately end up in an event store for querying and viewing. In a microservices approach, it’s key that different teams agree on a single logging format. There needs to be a consistent approach to viewing diagnostic events in the application.</p>
	<h3 id="id_Toc534713587" class="block_19">Health checks</h3>
	<p class="block_14">Health is different from diagnostics. Health is about the microservice reporting its current state to take appropriate actions. A good example is working with upgrade and deployment mechanisms to maintain availability. Although a service might currently be unhealthy due to a process crash or machine reboot, the service might still be operational. The last thing you need is to make this worse by performing an upgrade. The best approach is to do an investigation first or allow time for the microservice to recover. Health events from a microservice help us make informed decisions and, in effect, help create self-healing services.</p>
	<p class="block_17"><span class="text_5">In the </span><a href="index_split_014.html#id_Toc534713861" class="text_4">Implementing health checks in ASP.NET Core services</a><span class="text_5"> section of this guide, we explain how to use a new ASP.NET HealthChecks library in your microservices so they can report their state to a monitoring service to take appropriate actions.</span></p>
	<p class="block_17"><span class="text_5">You also have the option of using an excellent open-source library called Beat Pulse, available on </span><a href="https://github.com/Xabaril/BeatPulse" class="text_4">GitHub</a><span class="text_5"> and as a </span><a href="https://www.nuget.org/packages/BeatPulse/" class="text_4">NuGet package</a><span class="text_5">. This library also does health checks, with a twist, it handles two types of checks:</span></p>
	<ul class="list_">
	<li class="block_25"><b class="calibre1">Liveness</b>: Checks if the microservice is alive, that is, if it’s able to accept requests and respond.</li>
	<li class="block_25"><b class="calibre1">Readiness</b>: Checks if the microservice’s dependencies (Database, queue services, etc.) are themselves ready, so the microservice can do what it’s supposed to do.</li>
</ul>
	<h3 id="id_Toc534713588" class="block_19">Using diagnostics and logs event streams</h3>
	<p class="block_14">Logs provide information about how an application or service is running, including exceptions, warnings, and simple informational messages. Usually, each log is in a text format with one line per event, although exceptions also often show the stack trace across multiple lines.</p>
	<p class="block_14">In monolithic server-based applications, you can simply write logs to a file on disk (a logfile) and then analyze it with any tool. Since application execution is limited to a fixed server or VM, it generally isn’t too complex to analyze the flow of events. However, in a distributed application where multiple services are executed across many nodes in an orchestrator cluster, being able to correlate distributed events is a challenge.</p>
	<p class="block_17"><span class="text_5">A microservice-based application should not try to store the output stream of events or logfiles by itself, and not even try to manage the routing of the events to a central place. It should be transparent, meaning that each process should just write its event stream to a standard output that underneath will be collected by the execution environment infrastructure where it’s running. An example of these event stream routers is </span><a href="https://github.com/Azure/diagnostics-eventflow" class="text_4">Microsoft.Diagnostic.EventFlow</a><span class="text_5">, which collects event streams from multiple sources and publishes it to output systems. These can include simple standard output for a development environment or cloud systems like </span><a href="https://azure.microsoft.com/services/application-insights/" class="text_4">Application Insights</a><span class="text_5">, </span><a href="https://github.com/Azure/diagnostics-eventflow" class="text_4">OMS</a><span class="text_5"> (for on-premises applications), and </span><a href="https://docs.microsoft.com/azure/monitoring-and-diagnostics/azure-diagnostics" class="text_4">Azure Diagnostics</a><span class="text_5">. There are also good third-party log analysis platforms and tools that can search, alert, report, and monitor logs, even in real time, like </span><a href="https://www.splunk.com/goto/Splunk_Log_Management?ac=ga_usa_log_analysis_phrase_Mar17&amp;_kk=logs%20analysis&amp;gclid=CNzkzIrex9MCFYGHfgodW5YOtA" class="text_4">Splunk</a><span class="text_5">.</span></p>
	<h3 id="id_Toc534713589" class="block_19">Orchestrators managing health and diagnostics information</h3>
	<p class="block_14">When you create a microservice-based application, you need to deal with complexity. Of course, a single microservice is simple to deal with, but dozens or hundreds of types and thousands of instances of microservices is a complex problem. It isn’t just about building your microservice architecture—you also need high availability, addressability, resiliency, health, and diagnostics if you intend to have a stable and cohesive system.</p>
	<p class="block_14"><img src="images/image-27.png" alt="C:\Users\Miguel\source\repos\dotnet\docs\docs\standard\microservices-architecture\architect-microservice-container-applications\media\image22.png" class="calibre37"/></p>
	<p class="block_23"><span class="text_6">Figure 4-22</span><i class="calibre8">. A Microservice Platform is fundamental for an application’s health management</i></p>
	<p class="block_14">The complex problems shown in Figure 4-22 are very hard to solve by yourself. Development teams should focus on solving business problems and building custom applications with microservice-based approaches. They should not focus on solving complex infrastructure problems; if they did, the cost of any microservice-based application would be huge. Therefore, there are microservice-oriented platforms, referred to as orchestrators or microservice clusters, that try to solve the hard problems of building and running a service and using infrastructure resources efficiently. This reduces the complexities of building applications that use a microservices approach.</p>
	<p class="block_14">Different orchestrators might sound similar, but the diagnostics and health checks offered by each of them differ in features and state of maturity, sometimes depending on the OS platform, as explained in the next section.</p>
	<h2 id="id_Toc534713590" class="block_18">Additional resources</h2>
	<ul class="list_">
	<li class="block_20"><span class="text_2">The Twelve-Factor App. XI. Logs: Treat logs as event streams</span><span class="text_"><br class="calibre6"/></span><a href="https://12factor.net/logs" class="text_1">https://12factor.net/logs</a></li>
	<li class="block_20"><span class="text_2">Microsoft Diagnostic EventFlow Library</span><span class="text_"> GitHub repo.<br class="calibre6"/></span><a href="https://github.com/Azure/diagnostics-eventflow" class="text_1">https://github.com/Azure/diagnostics-eventflow</a></li>
	<li class="block_20"><span class="text_2">What is Azure Diagnostics</span><span class="text_"><br class="calibre6"/></span><a href="https://docs.microsoft.com/azure/azure-diagnostics" class="text_1">https://docs.microsoft.com/azure/azure-diagnostics</a></li>
	<li class="block_20"><span class="text_2">Connect Windows computers to the Log Analytics service in Azure</span><span class="text_"><br class="calibre6"/></span><a href="https://docs.microsoft.com/azure/log-analytics/log-analytics-windows-agents" class="text_1">https://docs.microsoft.com/azure/log-analytics/log-analytics-windows-agents</a></li>
	<li class="block_20"><span class="text_2">Logging What You Mean: Using the Semantic Logging Application Block</span><span class="text_"><br class="calibre6"/></span><a href="https://msdn.microsoft.com/library/dn440729(v=pandp.60).aspx" class="text_1">https://msdn.microsoft.com/library/dn440729(v=pandp.60).aspx</a></li>
	<li class="block_20"><span class="text_2">Splunk</span><span class="text_"> Official site.<br class="calibre6"/></span><a href="https://www.splunk.com/" class="text_1">https://www.splunk.com/</a></li>
	<li class="block_20"><span class="text_2">EventSource Class</span><span class="text_"> API for events tracing for Windows (ETW)<br class="calibre6"/></span><a href="https://docs.microsoft.com/dotnet/api/system.diagnostics.tracing.eventsource" class="text_1">https://docs.microsoft.com/dotnet/api/system.diagnostics.tracing.eventsource</a></li>
</ul>
	<h1 id="id_Toc534713591" class="block_24">Orchestrating microservices and multi-container applications for high scalability and availability</h1>
	<p class="block_14">Using orchestrators for production-ready applications is essential if your application is based on microservices or simply split across multiple containers. As introduced previously, in a microservice-based approach, each microservice owns its model and data so that it will be autonomous from a development and deployment point of view. But even if you have a more traditional application that’s composed of multiple services (like SOA), you’ll also have multiple containers or services comprising a single business application that need to be deployed as a distributed system. These kinds of systems are complex to scale out and manage; therefore, you absolutely need an orchestrator if you want to have a production-ready and scalable multi-container application.</p>
	<p class="block_14">Figure 4-23 illustrates deployment into a cluster of an application composed of multiple microservices (containers).</p>
	<p class="block_14"><img src="images/image-28.png" alt="C:\Users\Miguel\source\repos\dotnet\docs\docs\standard\microservices-architecture\architect-microservice-container-applications\media\image23.png" class="calibre38"/></p>
	<p class="block_23"><span class="text_6">Figure 4-23</span><i class="calibre8">. A cluster of containers</i></p>
	<p class="block_14">It looks like a logical approach. But how are you handling load-balancing, routing, and orchestrating these composed applications?</p>
	<p class="block_14">The plain Docker Engine in single Docker hosts meets the needs of managing single image instances on one host, but it falls short when it comes to managing multiple containers deployed on multiple hosts for more complex distributed applications. In most cases, you need a management platform that will automatically start containers, scale-out containers with multiple instances per image, suspend them or shut them down when needed, and ideally also control how they access resources like the network and data storage.</p>
	<p class="block_14">To go beyond the management of individual containers or very simple composed apps and move toward larger enterprise applications with microservices, you must turn to orchestration and clustering platforms.</p>
	<p class="block_14">From an architecture and development point of view, if you’re building large enterprise composed of microservices-based applications, it’s important to understand the following platforms and products that support advanced scenarios:</p>
	<p class="block_14"><b class="calibre5">Clusters and orchestrators.</b> When you need to scale out applications across many Docker hosts, as when a large microservice-based application, it’s critical to be able to manage all those hosts as a single cluster by abstracting the complexity of the underlying platform. That’s what the container clusters and orchestrators provide. Examples of orchestrators are Azure Service Fabric and Kubernetes. Kubernetes is available in Azure through Azure Kubernetes Service.</p>
	<p class="block_14"><b class="calibre5">Schedulers.</b> <i class="calibre15">Scheduling</i> means to have the capability for an administrator to launch containers in a cluster so they also provide a UI. A cluster scheduler has several responsibilities: to use the cluster’s resources efficiently, to set the constraints provided by the user, to efficiently load-balance containers across nodes or hosts, and to be robust against errors while providing high availability.</p>
	<p class="block_14">The concepts of a cluster and a scheduler are closely related, so the products provided by different vendors often provide both sets of capabilities. The following list shows the most important platform and software choices you have for clusters and schedulers. These orchestrators are generally offered in public clouds like Azure.</p>
	<h2 id="id_Toc534713592" class="block_18">Software platforms for container clustering, orchestration, and scheduling</h2>
	<p class="block_4" id="calibre_pb_5"> </p>
</body></html>
