<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
  <head>
    <title>Unknown</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<p class="block_14"><img src="images/Screen_Shot_2019-01-15_at_6.33.38_PM.png" alt="Image" class="calibre105"/>The values in the base docker-compose.yml file should not change because of different target deployment environments.</p>
	<p class="block_14">If you focus on the webmvc service definition, for instance, you can see how that information is much the same no matter what environment you might be targeting. You have the following information:</p>
	<ul class="list_">
	<li class="block_25">The service name: webmvc.</li>
	<li class="block_25">The container’s custom image: eshop/webmvc.</li>
	<li class="block_25">The command to build the custom Docker image, indicating which Dockerfile to use.</li>
	<li class="block_25">Dependencies on other services, so this container does not start until the other dependency containers have started.</li>
</ul>
	<p class="block_14">You can have additional configuration, but the important point is that in the base docker-compose.yml file, you just want to set the information that is common across environments. Then in the docker-compose.override.yml or similar files for production or staging, you should place configuration that is specific for each environment.</p>
	<p class="block_14"><img src="images/Screen_Shot_2019-01-15_at_6.35.47_PM.png" alt="Image" class="calibre106"/>Usually, the docker-compose.override.yml is used for your development environment, as in the following example from eShopOnContainers:</p>
	<p class="block_14"><img src="images/Screen_Shot_2019-01-15_at_6.35.55_PM.png" alt="Image" class="calibre107"/>In this example, the development override configuration exposes some ports to the host, defines environment variables with redirect URLs, and specifies connection strings for the development environment. These settings are all just for the development environment.</p>
	<p class="block_27"><span class="text_8">When you run </span><span class="text_9">docker-compose up</span><span class="text_8"> (or launch it from Visual Studio), the command reads the overrides automatically as if it were merging both files.</span></p>
	<p class="block_27"><span class="text_8">Suppose that you want another Compose file for the production environment, with different configuration values, ports or connection strings. You can create another override file, like file named </span><span class="text_9">docker-compose.prod.yml</span><span class="text_8"> with different settings and environment variables. That file might be stored in a different Git repo or managed and secured by a different team.</span></p>
	<h4 id="id_howtodeploywithaspecificoverridef" class="block_33">How to deploy with a specific override file</h4>
	<p class="block_14"><img src="images/Screen_Shot_2019-01-15_at_6.37.25_PM.png" alt="Image" class="calibre59"/>To use multiple override files, or an override file with a different name, you can use the -f option with the docker-compose command and specify the files. Compose merges files in the order they are specified on the command line. The following example shows how to deploy with override files.</p>
	<h4 id="id_usingenvironmentvariablesindockerco" class="block_33">Using environment variables in docker-compose files</h4>
	<p class="block_14"><img src="images/Screen_Shot_2019-01-15_at_6.37.31_PM.png" alt="Image" class="calibre59"/>It is convenient, especially in production environments, to be able to get configuration information from environment variables, as we have shown in previous examples. You can reference an environment variable in your docker-compose files using the syntax ${MY_VAR}. The following line from a docker-compose.prod.yml file shows how to reference the value of an environment variable.</p>
	<p class="block_14">Environment variables are created and initialized in different ways, depending on your host environment (Linux, Windows, Cloud cluster, etc.). However, a convenient approach is to use an .env file. The docker-compose files support declaring default environment variables in the .env file. These values for the environment variables are the default values. But they can be overridden by the values you might have defined in each of your environments (host OS or environment variables from your cluster). You place this .env file in the folder where the docker-compose command is executed from.</p>
	<p class="block_17"><span class="text_5"><img src="images/Screen_Shot_2019-01-15_at_6.37.38_PM.png" alt="Image" class="calibre108"/>The following example shows an .env file like the </span><a href="https://github.com/dotnet-architecture/eShopOnContainers/blob/master/.env" class="text_4">.env</a><span class="text_5"> file for the eShopOnContainers application.</span></p>
	<p class="block_14">Docker-compose expects each line in an .env file to be in the format &lt;variable&gt;=&lt;value&gt;.</p>
	<p class="block_14">Note that the values set in the runtime environment always override the values defined inside the .env file. In a similar way, values passed via command-line command arguments also override the default values set in the .env file.</p>
	<h4 class="block_33">Additional resources</h4>
	<ul class="list_">
	<li class="block_20"><span class="text_2">Overview of Docker Compose</span><span class="text_"><span class="calibre109">  </span></span><a href="https://docs.docker.com/compose/overview/" class="text_1">https://docs.docker.com/compose/overview/</a></li>
	<li class="block_20"><span class="text_2">Multiple Compose files</span><span class="text_"><span class="calibre109">  </span></span><a href="https://docs.docker.com/compose/extends/" class="text_1">https://docs.docker.com/compose/extends/#multiple-compose-files</a></li>
</ul>
	<h3 id="id_Toc534713667" class="block_19">Building optimized ASP.NET Core Docker images</h3>
	<p class="block_14"><img src="images/Screen_Shot_2019-01-15_at_6.37.45_PM.png" alt="Image" class="calibre110"/>If you are exploring Docker and .NET Core on sources on the Internet, you will find Dockerfiles that demonstrate the simplicity of building a Docker image by copying your source into a container. These examples suggest that by using a simple configuration, you can have a Docker image with the environment packaged with your application. The following example shows a simple Dockerfile in this vein.</p>
	<p class="block_14">A Dockerfile like this will work. However, you can substantially optimize your images, especially your production images.</p>
	<p class="block_27"><span class="text_8">In the container and microservices model, you are constantly starting containers. The typical way of using containers does not restart a sleeping container, because the container is disposable. Orchestrators (like Kubernetes and Azure Service Fabric) simply create new instances of images. What this means is that you would need to optimize by precompiling the application when it is built so the instantiation process will be faster. When the container is started, it should be ready to run. You should not restore and compile at run time, using </span><span class="text_9">dotnet restore</span><span class="text_8"> and </span><span class="text_9">dotnet build</span><span class="text_8"> commands from the dotnet CLI that, as you see in many blog posts about .NET Core and Docker.</span></p>
	<p class="block_14">The .NET team has been doing important work to make .NET Core and ASP.NET Core a container-optimized framework. Not only is .NET Core a lightweight framework with a small memory footprint; the team has focused on optimized Docker images for three main scenarios and published them in the Docker Hub registry at <span class="text_18">microsoft/dotnet</span>, beginning with version 2.1:</p>
	<ol class="list_1">
	<li class="block_25"><b class="calibre1">Development</b>: Where the priority is the ability to quickly interate and debug changes and size is secondary.</li>
	<li class="block_25"><b class="calibre1">Build</b>: The priority is compiling the application and includes binaries and other dependencies to optimize binaries.</li>
	<li class="block_25"><b class="calibre1">Production</b>: Where the focus is fast deploying and starting of containers, so these images are limited to the binaries and the content nedded to run the application.</li>
</ol>
	<p class="block_17"><span class="text_5">To achieve this, the .NET team is providing three basic variants in </span><a href="https://hub.docker.com/r/microsoft/dotnet/" class="text_4">microsoft/dotnet</a><span class="text_5"> (at Docker Hub):</span></p>
	<ol class="list_1">
	<li class="block_25"><b class="calibre1">sdk</b>: for the development and build scenarios.</li>
	<li class="block_25"><b class="calibre1">runtime</b>: for the production scenario and</li>
	<li class="block_20"><span class="text_2">runtime-deps</span><span class="text_">: for the production scenario of </span><a href="https://docs.microsoft.com/dotnet/core/deploying/index" class="text_1">self-contained applications</a><span class="text_">.</span></li>
</ol>
	<p class="block_14">Runtime images also provides automatic setting of aspnetcore_urls to port 80 and the pre-ngend cache of assemblies; to help in getting faster startup.</p>
	<h4 class="block_33">Additional resources</h4>
	<ul class="list_">
	<li class="block_20"><span class="text_2">Building Optimized Docker Images with ASP.NET Core</span><span class="text_"><span class="calibre109">  </span></span><a href="https://blogs.msdn.microsoft.com/stevelasker/2016/09/29/building-optimized-docker-images-with-asp-net-core/" class="text_1">https://blogs.msdn.microsoft.com/stevelasker/2016/09/29/building-optimized-docker-images-with-asp-net-core/</a></li>
	<li class="block_20"><span class="text_2">Building Docker Images for .NET Core Applications</span><span class="text_"><span class="calibre109">  </span></span><a href="https://docs.microsoft.com/en-us/dotnet/core/docker/building-net-docker-images" class="text_1">https://docs.microsoft.com/en-us/dotnet/core/docker/building-net-docker-images</a></li>
</ul>
	<h1 id="id_Toc534713668" class="block_24">Using a database server running as a container</h1>
	<p class="block_27"><span class="text_8">You can have your databases (SQL Server, PostgreSQL, MySQL, etc.) on regular standalone servers, in on-premises clusters, or in PaaS services in the cloud like Azure SQL DB. However, for development and test environments, having your databases running as containers is convenient, because you do not have any external dependency and simply running the </span><span class="text_9">docker-compose up</span><span class="text_8"> command starts the whole application. Having those databases as containers is also great for integration tests, because the database is started in the container and is always populated with the same sample data, so tests can be more predictable.</span></p>
	<h3 id="id_Toc534713669" class="block_19">SQL Server running as a container with a microservice-related database</h3>
	<p class="block_17"><span class="text_5">In eShopOnContainers, there is a container named sql.data defined in the </span><a href="https://github.com/dotnet-architecture/eShopOnContainers/blob/master/docker-compose.yml" class="text_4">docker-compose.yml</a><span class="text_5"> file that runs SQL Server for Linux with all the SQL Server databases needed for the microservices. (You could also have one SQL Server container for each database, but that would require more memory assigned to Docker.) The important point in microservices is that each microservice owns its related data, therefore its related SQL database in this case. But the databases can be anywhere.</span></p>
	<p class="block_27"><span class="text_8"><img src="images/Screen_Shot_2019-01-15_at_6.38.54_PM.png" alt="Image" class="calibre111"/>The SQL Server container in the sample application is configured with the following YAML code in the docker-compose.yml file, which is executed when you run </span><span class="text_9">docker-compose up</span><span class="text_8">. Note that the YAML code has consolidated configuration information from the generic docker-compose.yml file and the docker-compose.override.yml file. (Usually you would separate the environment settings from the base or static information related to the SQL Server image.)</span></p>
	<p class="block_27"><span class="text_8"><img src="images/Screen_Shot_2019-01-15_at_6.39.02_PM.png" alt="Image" class="calibre112"/>In a similar way, instead of using </span><span class="text_9">docker-compose</span><span class="text_8">, the following </span><span class="text_9">docker run</span><span class="text_8"> command can run that container:</span></p>
	<p class="block_27"><span class="text_8">However, if you are deploying a multi-container application like eShopOnContainers, it is more convenient to use the </span><span class="text_9">docker-compose up</span><span class="text_8"> command so that it deploys all the required containers for the application.</span></p>
	<p class="block_14">When you start this SQL Server container for the first time, the container initializes SQL Server with the password that you provide. Once SQL Server is running as a container, you can update the database by connecting through any regular SQL connection, such as from SQL Server Management Studio, Visual Studio, or C# code.</p>
	<p class="block_14">The eShopOnContainers application initializes each microservice database with sample data by seeding it with data on startup, as explained in the following section.</p>
	<p class="block_14">Having SQL Server running as a container is not just useful for a demo where you might not have access to an instance of SQL Server. As noted, it is also great for development and testing environments so that you can easily run integration tests starting from a clean SQL Server image and known data by seeding new sample data.</p>
	<h4 class="block_33">Additional resources</h4>
	<ul class="list_">
	<li class="block_20"><span class="text_2">Run the SQL Server Docker image on Linux, Mac, or Windows</span><span class="text_"><span class="calibre109">  </span></span><a href="https://docs.microsoft.com/sql/linux/sql-server-linux-setup-docker" class="text_1">https://docs.microsoft.com/sql/linux/sql-server-linux-setup-docker</a></li>
	<li class="block_20"><span class="text_2">Connect and query SQL Server on Linux with sqlcmd</span><span class="text_"><span class="calibre109">  </span></span><a href="https://docs.microsoft.com/sql/linux/sql-server-linux-connect-and-query-sqlcmd" class="text_1">https://docs.microsoft.com/sql/linux/sql-server-linux-connect-and-query-sqlcmd</a></li>
</ul>
	<h3 id="id_Toc534713670" class="block_19">Seeding with test data on Web application startup</h3>
	<p class="block_14"><img src="images/Screen_Shot_2019-01-15_at_6.39.10_PM.png" alt="Image" class="calibre113"/>To add data to the database when the application starts up, you can add code like the following to the Configure method in the Startup class of the Web API project:</p>
	<p class="block_14">The following code in the custom CatalogContextSeed class populates the data.</p>
	<p class="block_4" id="calibre_pb_9"> </p>
</body></html>
